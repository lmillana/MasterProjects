{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmillana/MasterProjects/blob/main/Machine%20Learning/%20Time%20Series%20Classification%20with%20RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cb9-4GDowmHi"
      },
      "source": [
        "# Clasificación de series temporale desde cero\n",
        "\n",
        "Entrenamiento de un clasificador de series temporales desde cero en el conjunto de datos FordA del archivo UCR/UEA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6Fy5gNhwmHl"
      },
      "source": [
        "## Introducción\n",
        "\n",
        "Este ejemplo muestra cómo realizar la clasificación de series temporales desde cero, partiendo de archivos de series temporales CSV sin procesar en disco.\n",
        "CSV en disco.\n",
        "\n",
        "Demostramos el flujo de trabajo con el conjunto de datos FordA de la base de datos\n",
        "[UCR/UEA archivo](https://www.cs.ucr.edu/%7Eeamonn/time_series_data_2018/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuBGJD6mwmHl"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQhtGVBU7gej",
        "outputId": "12f45541-ef6e-4268-e398-cffcd90e3c41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxyKpphMwmHm"
      },
      "outputs": [],
      "source": [
        "# instala las librerías necesarias para el proyecto\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.keras import layers\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, GRU, SimpleRNN,  Dense, Dropout\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BpoqJsRwmHn"
      },
      "source": [
        "\n",
        "## Cargar los datos: el dataset FordA\n",
        "\n",
        "### Descripción del dataset\n",
        "\n",
        "El conjunto de datos que utilizamos aquí se llama FordA.\n",
        "Los datos proceden del archivo de la UCR.\n",
        "El conjunto de datos contiene 3.601 instancias de entrenamiento y otras 1.320 instancias de prueba.\n",
        "Cada serie temporal corresponde a una medición del ruido del motor captada por un sensor del motor.\n",
        "Para esta tarea, el objetivo es detectar automáticamente la presencia de un problema específico en el motor.\n",
        "\n",
        "\n",
        "El problema es una **tarea de clasificación binaria equilibrada**. La descripción completa de este conjunto de datos [aquí](http://www.j-wichard.de/publications/FordPaper.pdf).\n",
        "\n",
        "### Leer los datos TSV\n",
        "\n",
        "Utilizaremos el archivo `FordA_TRAIN` para el entrenamiento y el archivo para las pruebas. La simplicidad de este conjunto de datos\n",
        "nos permite demostrar eficazmente cómo utilizar RNN y CNN para la clasificación de series temporales.\n",
        "En este archivo, la primera columna corresponde a la etiqueta."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## OPCION 1: dividimos entre df_train & df_test\n",
        "# habría que dividir después x_train, y_train & x_test, y_test\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "root_url = \"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/\"\n",
        "\n",
        "df_train = pd.read_csv(root_url + \"FordA_TRAIN.tsv\", sep= \"\\t\", header = None)\n",
        "df_test = pd.read_csv(root_url + \"FordA_TEST.tsv\", sep= \"\\t\", header = None)"
      ],
      "metadata": {
        "id": "r6aKrQUB-0-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "a7i24fuZDTYJ",
        "outputId": "11d286db-0f70-4890-ef70-0bfc6a8145f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0         1         2         3         4         5         6         7    \\\n",
              "0   -1 -0.140402  0.171641  0.302044  0.232804  0.033853 -0.224183 -0.469987   \n",
              "1   -1  0.334038  0.322253  0.453844  0.671852  0.887897  1.020469  1.059750   \n",
              "2   -1  0.716686  0.744367  0.725913  0.661325  0.555217  0.413585  0.246580   \n",
              "3    1  1.240282  1.331189  1.386596  1.383220  1.305979  1.142784  0.878613   \n",
              "4   -1 -1.159478 -1.204174 -1.167605 -1.033518 -0.818166 -0.558119 -0.299291   \n",
              "\n",
              "        8         9    ...       491       492       493       494       495  \\\n",
              "0 -0.645396 -0.617700  ... -0.319966  0.390903  0.974831  1.258717  1.143316   \n",
              "1  1.030290  0.950746  ...  0.435186 -0.346502 -0.924912 -1.208716 -1.247996   \n",
              "2  0.065273 -0.121109  ...  3.171020  2.276019  1.219548  0.081881 -1.050250   \n",
              "3  0.532291  0.140025  ... -0.820262 -1.124551 -1.302012 -1.340564 -1.271440   \n",
              "4 -0.093691  0.022770  ...  0.660853  0.441438  0.206176 -0.006941 -0.146919   \n",
              "\n",
              "        496       497       498       499       500  \n",
              "0  0.647092 -0.049582 -0.690402 -0.976596 -0.794263  \n",
              "1 -1.139974 -1.041772 -1.041772 -1.159614 -1.375659  \n",
              "2 -2.092881 -2.983269 -3.675281 -4.136622 -4.339612  \n",
              "3 -1.146352 -1.011328 -0.931222 -0.934498 -1.001288  \n",
              "4 -0.183082 -0.112382  0.008987  0.131413  0.186266  \n",
              "\n",
              "[5 rows x 501 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0978d1da-a393-410b-9e62-adbf31234d02\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>491</th>\n",
              "      <th>492</th>\n",
              "      <th>493</th>\n",
              "      <th>494</th>\n",
              "      <th>495</th>\n",
              "      <th>496</th>\n",
              "      <th>497</th>\n",
              "      <th>498</th>\n",
              "      <th>499</th>\n",
              "      <th>500</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>-0.140402</td>\n",
              "      <td>0.171641</td>\n",
              "      <td>0.302044</td>\n",
              "      <td>0.232804</td>\n",
              "      <td>0.033853</td>\n",
              "      <td>-0.224183</td>\n",
              "      <td>-0.469987</td>\n",
              "      <td>-0.645396</td>\n",
              "      <td>-0.617700</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.319966</td>\n",
              "      <td>0.390903</td>\n",
              "      <td>0.974831</td>\n",
              "      <td>1.258717</td>\n",
              "      <td>1.143316</td>\n",
              "      <td>0.647092</td>\n",
              "      <td>-0.049582</td>\n",
              "      <td>-0.690402</td>\n",
              "      <td>-0.976596</td>\n",
              "      <td>-0.794263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1</td>\n",
              "      <td>0.334038</td>\n",
              "      <td>0.322253</td>\n",
              "      <td>0.453844</td>\n",
              "      <td>0.671852</td>\n",
              "      <td>0.887897</td>\n",
              "      <td>1.020469</td>\n",
              "      <td>1.059750</td>\n",
              "      <td>1.030290</td>\n",
              "      <td>0.950746</td>\n",
              "      <td>...</td>\n",
              "      <td>0.435186</td>\n",
              "      <td>-0.346502</td>\n",
              "      <td>-0.924912</td>\n",
              "      <td>-1.208716</td>\n",
              "      <td>-1.247996</td>\n",
              "      <td>-1.139974</td>\n",
              "      <td>-1.041772</td>\n",
              "      <td>-1.041772</td>\n",
              "      <td>-1.159614</td>\n",
              "      <td>-1.375659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1</td>\n",
              "      <td>0.716686</td>\n",
              "      <td>0.744367</td>\n",
              "      <td>0.725913</td>\n",
              "      <td>0.661325</td>\n",
              "      <td>0.555217</td>\n",
              "      <td>0.413585</td>\n",
              "      <td>0.246580</td>\n",
              "      <td>0.065273</td>\n",
              "      <td>-0.121109</td>\n",
              "      <td>...</td>\n",
              "      <td>3.171020</td>\n",
              "      <td>2.276019</td>\n",
              "      <td>1.219548</td>\n",
              "      <td>0.081881</td>\n",
              "      <td>-1.050250</td>\n",
              "      <td>-2.092881</td>\n",
              "      <td>-2.983269</td>\n",
              "      <td>-3.675281</td>\n",
              "      <td>-4.136622</td>\n",
              "      <td>-4.339612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1.240282</td>\n",
              "      <td>1.331189</td>\n",
              "      <td>1.386596</td>\n",
              "      <td>1.383220</td>\n",
              "      <td>1.305979</td>\n",
              "      <td>1.142784</td>\n",
              "      <td>0.878613</td>\n",
              "      <td>0.532291</td>\n",
              "      <td>0.140025</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.820262</td>\n",
              "      <td>-1.124551</td>\n",
              "      <td>-1.302012</td>\n",
              "      <td>-1.340564</td>\n",
              "      <td>-1.271440</td>\n",
              "      <td>-1.146352</td>\n",
              "      <td>-1.011328</td>\n",
              "      <td>-0.931222</td>\n",
              "      <td>-0.934498</td>\n",
              "      <td>-1.001288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1</td>\n",
              "      <td>-1.159478</td>\n",
              "      <td>-1.204174</td>\n",
              "      <td>-1.167605</td>\n",
              "      <td>-1.033518</td>\n",
              "      <td>-0.818166</td>\n",
              "      <td>-0.558119</td>\n",
              "      <td>-0.299291</td>\n",
              "      <td>-0.093691</td>\n",
              "      <td>0.022770</td>\n",
              "      <td>...</td>\n",
              "      <td>0.660853</td>\n",
              "      <td>0.441438</td>\n",
              "      <td>0.206176</td>\n",
              "      <td>-0.006941</td>\n",
              "      <td>-0.146919</td>\n",
              "      <td>-0.183082</td>\n",
              "      <td>-0.112382</td>\n",
              "      <td>0.008987</td>\n",
              "      <td>0.131413</td>\n",
              "      <td>0.186266</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 501 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0978d1da-a393-410b-9e62-adbf31234d02')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0978d1da-a393-410b-9e62-adbf31234d02 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0978d1da-a393-410b-9e62-adbf31234d02');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f0d523f2-d7cd-45c1-bc6e-54652f0ca323\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f0d523f2-d7cd-45c1-bc6e-54652f0ca323')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f0d523f2-d7cd-45c1-bc6e-54652f0ca323 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KP54Gk9_wmHn"
      },
      "outputs": [],
      "source": [
        "## OPCION 2: dividimos x_train, y_train & x_test, y_test\n",
        "\n",
        "# lee un TSV\n",
        "# utiliza numpy o pandas para leerlo\n",
        "def readucr (filename):\n",
        "  data = np.loadtxt(filename, delimiter = \"\\t\")\n",
        "  y = data[:, 0]\n",
        "  x = data [:, 1:]\n",
        "  return x, y.astype(int)\n",
        "\n",
        "\n",
        "root_url = \"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/\"\n",
        "\n",
        "# lee un TSV\n",
        "# utiliza numpy o pandas para leerlo\n",
        "\n",
        "# obtén x_train, x_test, y_train, y_test\n",
        "x_train, y_train = readucr (root_url + \"FordA_TRAIN.tsv\") #500\n",
        "x_test, y_test = readucr (root_url + \"FordA_TEST.tsv\") #500\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## LONGITUD\n",
        "print(x_train.shape) #(3601, 500)\n",
        "print(y_train.shape) #(3601,)\n",
        "print(x_test.shape) #(1320, 500)\n",
        "print(y_test.shape) #(1320,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "al2r1SW3ad-K",
        "outputId": "4021056a-2b67-44b4-cc3a-fb999c09d3e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3601, 500)\n",
            "(3601,)\n",
            "(1320, 500)\n",
            "(1320,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Comprobamos que los datos de entrenamiento están BALANCEADOS\n",
        "\n",
        "val, frec = np.unique(y_train, return_counts=True)\n",
        "\n",
        "print(val, frec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-Qjt1apDvJm",
        "outputId": "4f0c8309-c180-4071-a4c4-3044ad982175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1  1] [1846 1755]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9z3-3LBwmHn"
      },
      "source": [
        "## Visualizar los datos\n",
        "\n",
        "Aquí visualizamos un ejemplo de serie temporal para cada clase del conjunto de datos."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tienes que tener en cuenta las clases que hay y visualizar las series de cada clase\n",
        "# no tine que ser igual el gráfico\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class1 = df_train[df_train[0] == 1]\n",
        "class_1 = df_train[df_train[0] == -1]\n",
        "\n"
      ],
      "metadata": {
        "id": "jeECUk4lCwZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzrAOhyFwmHo"
      },
      "source": [
        "## Estandarizar los datos\n",
        "\n",
        "Nuestras series temporales ya tienen una única longitud (500). Sin embargo, sus valores\n",
        "suelen estar en varios rangos. Esto no es lo ideal para una red neuronal;\n",
        "en general, deberíamos intentar normalizar los valores de entrada.\n",
        "\n",
        "Para este conjunto de datos concreto, los datos ya están normalizados en z: cada muestra de serie temporal\n",
        "tiene una media igual a cero y una desviación estándar igual a uno.\n",
        "\n",
        "Este tipo de normalización es muy común en los problemas de clasificación de series temporales.\n",
        "[Bagnall et al. (2016)](https://link.springer.com/article/10.1007/s10618-016-0483-9).\n",
        "\n",
        "Tenga en cuenta que los datos de series temporales utilizados aquí son univariantes, lo que significa que sólo tenemos un canal\n",
        "por ejemplo de serie temporal.\n",
        "Por lo tanto, transformaremos la serie temporal en una multivariante con un canal\n",
        "utilizando una simple remodelación a través de numpy.\n",
        "Esto nos permitirá construir un modelo fácilmente aplicable a series temporales multivariantes.\n",
        "multivariantes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMwIEleWwmHo"
      },
      "outputs": [],
      "source": [
        "# Utiliza el reshape en x_test y x_train\n",
        "# x_train tiene que ser de la forma (x_train.shape[0],x_train.shape[1],1)\n",
        "\n",
        "## reshape((array que cambiamos, new shape, num canal))\n",
        "## old: (3601, 500)\n",
        "x_train = x_train.reshape((x_train.shape[0],x_train.shape[1],1) )\n",
        "\n",
        "# x_test tiene que ser de la forma (x_test.shape[0],x_test.shape[1],1)\n",
        "## old: (1320, 500)\n",
        "x_test = x_test.reshape((x_test.shape[0],x_test.shape[1],1))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('new shape x_train: ', x_train.shape)\n",
        "print('new shape x_test: ', x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJSWv8yJfe5l",
        "outputId": "d638f79e-8ad9-4de4-81c3-842e51430789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new shape x_train:  (3601, 500, 1)\n",
            "new shape x_test:  (1320, 500, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCdJ4N5IwmHo"
      },
      "source": [
        "Por último, para utilizar `sparse_categorical_crossentropy`, tendremos que contar el número de clases de antemano."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnBG_op5wmHp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "414fdb3e-365f-4d42-91c9-4f2e1d126baf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tenemos 2 clases: [-1  1]\n"
          ]
        }
      ],
      "source": [
        "num_classes = np.unique(y_train) # cuenta el numero de clases\n",
        "\n",
        "print(f'Tenemos {len(num_classes)} clases: {num_classes}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktsenQtIwmHp"
      },
      "source": [
        "Ahora barajamos el conjunto de entrenamiento porque vamos a utilizar la opción `validation_split`\n",
        "más tarde cuando entrenemos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCnK7BptwmHp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff5ed747-1ad6-46dc-c4c4-3aed29da996b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3601, 500, 1), (3601,))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# para barajar los datos, puedes utilizar np.random.permutation(longitud datos train)\n",
        "idx = np.random.permutation(len(x_train)) # utiliza lo anterior para generar un índice aleatorio\n",
        "\n",
        "# separa cada train con ese índice\n",
        "x_train = x_train[idx]\n",
        "y_train = y_train[idx]\n",
        "\n",
        "x_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izF_6h9woE-F",
        "outputId": "70759bf5-760d-4bc9-8538-d429b5c10a81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  1, -1, ...,  1, -1, -1])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKcXX4FlwmHp"
      },
      "source": [
        "Se normalizan las etiquetas a números enteros positivos.\n",
        "Las etiquetas esperadas serán entonces 0 y 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3FBzs3zwmHp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f8be118-d7a6-466d-dc0c-413e3da108dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# para normalizar, tienes que quedarte con los valores de y_train == -1\n",
        "# estos valores van a ser ahora 0\n",
        "\n",
        "y_train = np.where(y_train == -1, 0, y_train)\n",
        "y_test = np.where(y_test == -1,0, y_test)\n",
        "\n",
        "y_train\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PbfRPwGwmHp"
      },
      "source": [
        "## Construyendo el modelo\n",
        "\n",
        "En este punto, se pueden crear muchos tipos.\n",
        "\n",
        "Para series temporales puedes utilizar las siguientes:\n",
        "- SimpleRNN\n",
        "- LSTM\n",
        "- GRU\n",
        "- Conv1D\n",
        "\n",
        "Y algunas más que no vamos a hablar aquí.\n",
        "\n",
        "Intenta probar con RNN, LSTM y GRU por sencillez."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecmfOSA0sjLV",
        "outputId": "30ad7361-10ce-48af-b396-0e54403cb12b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfYte_oqwmHp"
      },
      "outputs": [],
      "source": [
        "#from keras.models import Sequential\n",
        "#from keras.layers import Embedding, LSTM, GRU, SimpleRNN,  Dense\n",
        "\n",
        "# @title PRIMER MODELO: RNN SIMPLE\n",
        "\n",
        "input_shape = (x_train.shape[1], 1) #datos de entrada\n",
        "\n",
        "RNN = Sequential()\n",
        "\n",
        "RNN.add(SimpleRNN(32, input_shape=input_shape)) # Capa RNN, 64 vectores\n",
        "RNN.add(Dropout(0.5)) #Prevenimos sobreajuste\n",
        "RNN.add(Dense(1, activation='sigmoid'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKP_UN-pwmHq"
      },
      "outputs": [],
      "source": [
        "# @title ENTRENAMIENTO\n",
        "\n",
        "## CREAMOS MODELO:\n",
        "# compila el modelo eligiendo optimizer, loss y metrics\n",
        "RNN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## ENTRENAMOS:\n",
        "\n",
        "# Define las épocas y batch_size\n",
        "epochs = 200 #muchos datos por lo que se necesitan muchas epochs\n",
        "batch_size = 64\n",
        "\n",
        "# entrena el modelo y almacena el entrenamiento en la variable history\n",
        "history = RNN.fit(x_train, y_train,\n",
        "                  epochs= epochs,\n",
        "                  batch_size=batch_size,\n",
        "                  validation_split= 0.2)\n",
        "\n",
        "\n",
        "# guarda el modelo en .h5\n",
        "RNN.save('RNN.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bj0lN1XeqLDe",
        "outputId": "eef949fe-334e-4726-e98c-ff39ac58127f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "45/45 [==============================] - 9s 129ms/step - loss: 0.7133 - acc: 0.5170 - val_loss: 0.6931 - val_acc: 0.5035\n",
            "Epoch 2/200\n",
            "45/45 [==============================] - 5s 103ms/step - loss: 0.7090 - acc: 0.5010 - val_loss: 0.6927 - val_acc: 0.5090\n",
            "Epoch 3/200\n",
            "45/45 [==============================] - 6s 126ms/step - loss: 0.7022 - acc: 0.5212 - val_loss: 0.6919 - val_acc: 0.5284\n",
            "Epoch 4/200\n",
            "45/45 [==============================] - 4s 100ms/step - loss: 0.6972 - acc: 0.5097 - val_loss: 0.6920 - val_acc: 0.5312\n",
            "Epoch 5/200\n",
            "45/45 [==============================] - 6s 131ms/step - loss: 0.7047 - acc: 0.5073 - val_loss: 0.7004 - val_acc: 0.5035\n",
            "Epoch 6/200\n",
            "45/45 [==============================] - 4s 98ms/step - loss: 0.7067 - acc: 0.4986 - val_loss: 0.6919 - val_acc: 0.5243\n",
            "Epoch 7/200\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.7048 - acc: 0.5052 - val_loss: 0.6924 - val_acc: 0.5326\n",
            "Epoch 8/200\n",
            "45/45 [==============================] - 6s 123ms/step - loss: 0.7056 - acc: 0.5000 - val_loss: 0.6930 - val_acc: 0.4938\n",
            "Epoch 9/200\n",
            "45/45 [==============================] - 4s 98ms/step - loss: 0.6985 - acc: 0.4965 - val_loss: 0.6921 - val_acc: 0.4951\n",
            "Epoch 10/200\n",
            "45/45 [==============================] - 5s 121ms/step - loss: 0.6969 - acc: 0.5094 - val_loss: 0.6918 - val_acc: 0.5021\n",
            "Epoch 11/200\n",
            "45/45 [==============================] - 5s 99ms/step - loss: 0.6953 - acc: 0.5017 - val_loss: 0.6918 - val_acc: 0.5132\n",
            "Epoch 12/200\n",
            "45/45 [==============================] - 4s 98ms/step - loss: 0.6936 - acc: 0.5135 - val_loss: 0.6920 - val_acc: 0.5007\n",
            "Epoch 13/200\n",
            "45/45 [==============================] - 5s 120ms/step - loss: 0.6958 - acc: 0.5083 - val_loss: 0.6928 - val_acc: 0.5326\n",
            "Epoch 14/200\n",
            "45/45 [==============================] - 4s 97ms/step - loss: 0.6971 - acc: 0.5031 - val_loss: 0.6925 - val_acc: 0.5090\n",
            "Epoch 15/200\n",
            "45/45 [==============================] - 5s 103ms/step - loss: 0.6947 - acc: 0.5087 - val_loss: 0.6918 - val_acc: 0.5062\n",
            "Epoch 16/200\n",
            "45/45 [==============================] - 5s 117ms/step - loss: 0.6940 - acc: 0.5260 - val_loss: 0.6921 - val_acc: 0.5187\n",
            "Epoch 17/200\n",
            "45/45 [==============================] - 4s 97ms/step - loss: 0.6913 - acc: 0.5271 - val_loss: 0.6920 - val_acc: 0.5187\n",
            "Epoch 18/200\n",
            "45/45 [==============================] - 5s 123ms/step - loss: 0.6951 - acc: 0.5122 - val_loss: 0.6920 - val_acc: 0.5160\n",
            "Epoch 19/200\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 0.6937 - acc: 0.5222 - val_loss: 0.6920 - val_acc: 0.4993\n",
            "Epoch 20/200\n",
            "45/45 [==============================] - 8s 184ms/step - loss: 0.6934 - acc: 0.5167 - val_loss: 0.6918 - val_acc: 0.4993\n",
            "Epoch 21/200\n",
            "45/45 [==============================] - 4s 100ms/step - loss: 0.6917 - acc: 0.5188 - val_loss: 0.6916 - val_acc: 0.5229\n",
            "Epoch 22/200\n",
            "45/45 [==============================] - 5s 100ms/step - loss: 0.6955 - acc: 0.5087 - val_loss: 0.6918 - val_acc: 0.5215\n",
            "Epoch 23/200\n",
            "45/45 [==============================] - 5s 120ms/step - loss: 0.6895 - acc: 0.5382 - val_loss: 0.6915 - val_acc: 0.5007\n",
            "Epoch 24/200\n",
            "45/45 [==============================] - 6s 123ms/step - loss: 0.6990 - acc: 0.5035 - val_loss: 0.7018 - val_acc: 0.5104\n",
            "Epoch 25/200\n",
            "45/45 [==============================] - 5s 122ms/step - loss: 0.7156 - acc: 0.5045 - val_loss: 0.7022 - val_acc: 0.4938\n",
            "Epoch 26/200\n",
            "45/45 [==============================] - 4s 98ms/step - loss: 0.7076 - acc: 0.5135 - val_loss: 0.6936 - val_acc: 0.5007\n",
            "Epoch 27/200\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 0.7092 - acc: 0.5000 - val_loss: 0.6993 - val_acc: 0.4896\n",
            "Epoch 28/200\n",
            "45/45 [==============================] - 5s 122ms/step - loss: 0.7105 - acc: 0.4865 - val_loss: 0.6919 - val_acc: 0.5146\n",
            "Epoch 29/200\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.6993 - acc: 0.5215 - val_loss: 0.6935 - val_acc: 0.5132\n",
            "Epoch 30/200\n",
            "45/45 [==============================] - 6s 124ms/step - loss: 0.7047 - acc: 0.4997 - val_loss: 0.6936 - val_acc: 0.5104\n",
            "Epoch 31/200\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.7018 - acc: 0.4917 - val_loss: 0.6934 - val_acc: 0.5118\n",
            "Epoch 32/200\n",
            "45/45 [==============================] - 4s 99ms/step - loss: 0.6964 - acc: 0.5132 - val_loss: 0.6934 - val_acc: 0.5201\n",
            "Epoch 33/200\n",
            "45/45 [==============================] - 5s 122ms/step - loss: 0.6989 - acc: 0.4979 - val_loss: 0.6936 - val_acc: 0.4896\n",
            "Epoch 34/200\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 0.6958 - acc: 0.5017 - val_loss: 0.6935 - val_acc: 0.4993\n",
            "Epoch 35/200\n",
            "45/45 [==============================] - 6s 143ms/step - loss: 0.6978 - acc: 0.4872 - val_loss: 0.6931 - val_acc: 0.5160\n",
            "Epoch 36/200\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.6928 - acc: 0.5194 - val_loss: 0.6931 - val_acc: 0.5160\n",
            "Epoch 37/200\n",
            "45/45 [==============================] - 4s 98ms/step - loss: 0.6959 - acc: 0.4944 - val_loss: 0.6930 - val_acc: 0.5160\n",
            "Epoch 38/200\n",
            "45/45 [==============================] - 6s 124ms/step - loss: 0.6946 - acc: 0.4979 - val_loss: 0.6931 - val_acc: 0.5160\n",
            "Epoch 39/200\n",
            "45/45 [==============================] - 5s 101ms/step - loss: 0.6944 - acc: 0.5063 - val_loss: 0.6930 - val_acc: 0.5160\n",
            "Epoch 40/200\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.6935 - acc: 0.5090 - val_loss: 0.6934 - val_acc: 0.4688\n",
            "Epoch 41/200\n",
            "45/45 [==============================] - 5s 117ms/step - loss: 0.6932 - acc: 0.5128 - val_loss: 0.6932 - val_acc: 0.5160\n",
            "Epoch 42/200\n",
            "45/45 [==============================] - 4s 98ms/step - loss: 0.6940 - acc: 0.5097 - val_loss: 0.6931 - val_acc: 0.5201\n",
            "Epoch 43/200\n",
            "45/45 [==============================] - 5s 123ms/step - loss: 0.6953 - acc: 0.4941 - val_loss: 0.6938 - val_acc: 0.4938\n",
            "Epoch 44/200\n",
            "45/45 [==============================] - 4s 99ms/step - loss: 0.6938 - acc: 0.4976 - val_loss: 0.6933 - val_acc: 0.5118\n",
            "Epoch 45/200\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.6940 - acc: 0.5101 - val_loss: 0.6932 - val_acc: 0.5104\n",
            "Epoch 46/200\n",
            "45/45 [==============================] - 6s 125ms/step - loss: 0.6939 - acc: 0.5087 - val_loss: 0.6930 - val_acc: 0.5118\n",
            "Epoch 47/200\n",
            "45/45 [==============================] - 5s 100ms/step - loss: 0.6938 - acc: 0.5014 - val_loss: 0.6929 - val_acc: 0.5160\n",
            "Epoch 48/200\n",
            "45/45 [==============================] - 6s 136ms/step - loss: 0.6938 - acc: 0.5194 - val_loss: 0.6930 - val_acc: 0.5118\n",
            "Epoch 49/200\n",
            "45/45 [==============================] - 4s 99ms/step - loss: 0.6927 - acc: 0.5066 - val_loss: 0.6930 - val_acc: 0.5160\n",
            "Epoch 50/200\n",
            "45/45 [==============================] - 5s 103ms/step - loss: 0.6940 - acc: 0.5066 - val_loss: 0.6931 - val_acc: 0.5132\n",
            "Epoch 51/200\n",
            "45/45 [==============================] - 6s 124ms/step - loss: 0.6934 - acc: 0.5087 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 52/200\n",
            "45/45 [==============================] - 5s 109ms/step - loss: 0.6948 - acc: 0.4844 - val_loss: 0.6928 - val_acc: 0.5160\n",
            "Epoch 53/200\n",
            "45/45 [==============================] - 6s 123ms/step - loss: 0.6943 - acc: 0.5108 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 54/200\n",
            "45/45 [==============================] - 4s 99ms/step - loss: 0.6941 - acc: 0.5003 - val_loss: 0.6929 - val_acc: 0.5160\n",
            "Epoch 55/200\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 0.6927 - acc: 0.5118 - val_loss: 0.6928 - val_acc: 0.5160\n",
            "Epoch 56/200\n",
            "45/45 [==============================] - 5s 122ms/step - loss: 0.6939 - acc: 0.5035 - val_loss: 0.6928 - val_acc: 0.5160\n",
            "Epoch 57/200\n",
            "45/45 [==============================] - 5s 103ms/step - loss: 0.6924 - acc: 0.5170 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 58/200\n",
            "45/45 [==============================] - 6s 124ms/step - loss: 0.6927 - acc: 0.5122 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 59/200\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 0.6940 - acc: 0.5156 - val_loss: 0.6929 - val_acc: 0.5160\n",
            "Epoch 60/200\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 0.6938 - acc: 0.4913 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 61/200\n",
            "45/45 [==============================] - 6s 123ms/step - loss: 0.6934 - acc: 0.5167 - val_loss: 0.6929 - val_acc: 0.5118\n",
            "Epoch 62/200\n",
            "45/45 [==============================] - 4s 99ms/step - loss: 0.6931 - acc: 0.5014 - val_loss: 0.6929 - val_acc: 0.5146\n",
            "Epoch 63/200\n",
            "45/45 [==============================] - 6s 131ms/step - loss: 0.6933 - acc: 0.4948 - val_loss: 0.6926 - val_acc: 0.5160\n",
            "Epoch 64/200\n",
            "45/45 [==============================] - 5s 101ms/step - loss: 0.6930 - acc: 0.5101 - val_loss: 0.6926 - val_acc: 0.5160\n",
            "Epoch 65/200\n",
            "45/45 [==============================] - 5s 101ms/step - loss: 0.6932 - acc: 0.5083 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 66/200\n",
            "45/45 [==============================] - 5s 122ms/step - loss: 0.6935 - acc: 0.5024 - val_loss: 0.6926 - val_acc: 0.5160\n",
            "Epoch 67/200\n",
            "45/45 [==============================] - 5s 112ms/step - loss: 0.6936 - acc: 0.5000 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 68/200\n",
            "45/45 [==============================] - 6s 133ms/step - loss: 0.6929 - acc: 0.5146 - val_loss: 0.6926 - val_acc: 0.5160\n",
            "Epoch 69/200\n",
            "45/45 [==============================] - 5s 101ms/step - loss: 0.6936 - acc: 0.5142 - val_loss: 0.6928 - val_acc: 0.5160\n",
            "Epoch 70/200\n",
            "45/45 [==============================] - 4s 100ms/step - loss: 0.6937 - acc: 0.5021 - val_loss: 0.6928 - val_acc: 0.5160\n",
            "Epoch 71/200\n",
            "45/45 [==============================] - 6s 124ms/step - loss: 0.6932 - acc: 0.5063 - val_loss: 0.6926 - val_acc: 0.5160\n",
            "Epoch 72/200\n",
            "45/45 [==============================] - 6s 124ms/step - loss: 0.6929 - acc: 0.5125 - val_loss: 0.6926 - val_acc: 0.5160\n",
            "Epoch 73/200\n",
            "45/45 [==============================] - 5s 123ms/step - loss: 0.6934 - acc: 0.5003 - val_loss: 0.6926 - val_acc: 0.5160\n",
            "Epoch 74/200\n",
            "45/45 [==============================] - 4s 99ms/step - loss: 0.6932 - acc: 0.5149 - val_loss: 0.6928 - val_acc: 0.5146\n",
            "Epoch 75/200\n",
            "45/45 [==============================] - 5s 101ms/step - loss: 0.6936 - acc: 0.5125 - val_loss: 0.6926 - val_acc: 0.5160\n",
            "Epoch 76/200\n",
            "45/45 [==============================] - 6s 124ms/step - loss: 0.6941 - acc: 0.4885 - val_loss: 0.6925 - val_acc: 0.5160\n",
            "Epoch 77/200\n",
            "45/45 [==============================] - 4s 99ms/step - loss: 0.6926 - acc: 0.5153 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 78/200\n",
            "45/45 [==============================] - 5s 120ms/step - loss: 0.6938 - acc: 0.4885 - val_loss: 0.6928 - val_acc: 0.5146\n",
            "Epoch 79/200\n",
            "45/45 [==============================] - 5s 101ms/step - loss: 0.6937 - acc: 0.4896 - val_loss: 0.6926 - val_acc: 0.5160\n",
            "Epoch 80/200\n",
            "45/45 [==============================] - 4s 98ms/step - loss: 0.6931 - acc: 0.5132 - val_loss: 0.6928 - val_acc: 0.5160\n",
            "Epoch 81/200\n",
            "45/45 [==============================] - 6s 128ms/step - loss: 0.6937 - acc: 0.5028 - val_loss: 0.6926 - val_acc: 0.5160\n",
            "Epoch 82/200\n",
            "45/45 [==============================] - 4s 98ms/step - loss: 0.6931 - acc: 0.5118 - val_loss: 0.6926 - val_acc: 0.5160\n",
            "Epoch 83/200\n",
            "45/45 [==============================] - 7s 161ms/step - loss: 0.6932 - acc: 0.5010 - val_loss: 0.6925 - val_acc: 0.5160\n",
            "Epoch 84/200\n",
            "45/45 [==============================] - 4s 99ms/step - loss: 0.6930 - acc: 0.5073 - val_loss: 0.6929 - val_acc: 0.5312\n",
            "Epoch 85/200\n",
            "45/45 [==============================] - 5s 100ms/step - loss: 0.6939 - acc: 0.4986 - val_loss: 0.6926 - val_acc: 0.5160\n",
            "Epoch 86/200\n",
            "45/45 [==============================] - 5s 122ms/step - loss: 0.6939 - acc: 0.4979 - val_loss: 0.6925 - val_acc: 0.5160\n",
            "Epoch 87/200\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 0.6941 - acc: 0.5042 - val_loss: 0.6924 - val_acc: 0.5160\n",
            "Epoch 88/200\n",
            "45/45 [==============================] - 6s 134ms/step - loss: 0.6941 - acc: 0.5056 - val_loss: 0.6925 - val_acc: 0.5160\n",
            "Epoch 89/200\n",
            "45/45 [==============================] - 5s 111ms/step - loss: 0.6935 - acc: 0.5059 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 90/200\n",
            "45/45 [==============================] - 5s 104ms/step - loss: 0.6938 - acc: 0.5024 - val_loss: 0.6926 - val_acc: 0.5160\n",
            "Epoch 91/200\n",
            "45/45 [==============================] - 5s 118ms/step - loss: 0.6934 - acc: 0.5076 - val_loss: 0.6928 - val_acc: 0.5160\n",
            "Epoch 92/200\n",
            "45/45 [==============================] - 4s 98ms/step - loss: 0.6939 - acc: 0.5017 - val_loss: 0.6928 - val_acc: 0.5173\n",
            "Epoch 93/200\n",
            "45/45 [==============================] - 5s 121ms/step - loss: 0.6948 - acc: 0.4889 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 94/200\n",
            "45/45 [==============================] - 4s 98ms/step - loss: 0.6937 - acc: 0.5073 - val_loss: 0.6926 - val_acc: 0.5160\n",
            "Epoch 95/200\n",
            "45/45 [==============================] - 4s 98ms/step - loss: 0.6939 - acc: 0.4986 - val_loss: 0.6929 - val_acc: 0.5160\n",
            "Epoch 96/200\n",
            "45/45 [==============================] - 5s 122ms/step - loss: 0.6934 - acc: 0.5031 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 97/200\n",
            "45/45 [==============================] - 4s 98ms/step - loss: 0.6932 - acc: 0.5167 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 98/200\n",
            "45/45 [==============================] - 5s 111ms/step - loss: 0.6929 - acc: 0.5125 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 99/200\n",
            "45/45 [==============================] - 5s 109ms/step - loss: 0.6936 - acc: 0.5076 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 100/200\n",
            "45/45 [==============================] - 4s 99ms/step - loss: 0.6928 - acc: 0.5156 - val_loss: 0.6926 - val_acc: 0.5160\n",
            "Epoch 101/200\n",
            "45/45 [==============================] - 6s 127ms/step - loss: 0.6936 - acc: 0.5038 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 102/200\n",
            "45/45 [==============================] - 4s 98ms/step - loss: 0.6928 - acc: 0.5076 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 103/200\n",
            "45/45 [==============================] - 4s 99ms/step - loss: 0.6933 - acc: 0.5097 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 104/200\n",
            "45/45 [==============================] - 5s 119ms/step - loss: 0.6926 - acc: 0.5146 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 105/200\n",
            "45/45 [==============================] - 5s 101ms/step - loss: 0.6940 - acc: 0.4969 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 106/200\n",
            "45/45 [==============================] - 5s 121ms/step - loss: 0.6933 - acc: 0.5049 - val_loss: 0.6926 - val_acc: 0.5160\n",
            "Epoch 107/200\n",
            "45/45 [==============================] - 5s 100ms/step - loss: 0.6933 - acc: 0.4944 - val_loss: 0.6926 - val_acc: 0.5160\n",
            "Epoch 108/200\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 0.6941 - acc: 0.5045 - val_loss: 0.6926 - val_acc: 0.5160\n",
            "Epoch 109/200\n",
            "45/45 [==============================] - 6s 123ms/step - loss: 0.6934 - acc: 0.5038 - val_loss: 0.6925 - val_acc: 0.5160\n",
            "Epoch 110/200\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.6934 - acc: 0.5073 - val_loss: 0.6925 - val_acc: 0.5160\n",
            "Epoch 111/200\n",
            "45/45 [==============================] - 6s 123ms/step - loss: 0.6929 - acc: 0.5188 - val_loss: 0.6925 - val_acc: 0.5146\n",
            "Epoch 112/200\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.6929 - acc: 0.5108 - val_loss: 0.6923 - val_acc: 0.5160\n",
            "Epoch 113/200\n",
            "45/45 [==============================] - 5s 107ms/step - loss: 0.6935 - acc: 0.4934 - val_loss: 0.6925 - val_acc: 0.5104\n",
            "Epoch 114/200\n",
            "45/45 [==============================] - 6s 123ms/step - loss: 0.6935 - acc: 0.5045 - val_loss: 0.6923 - val_acc: 0.5160\n",
            "Epoch 115/200\n",
            "45/45 [==============================] - 5s 121ms/step - loss: 0.6930 - acc: 0.5128 - val_loss: 0.6923 - val_acc: 0.5201\n",
            "Epoch 116/200\n",
            "45/45 [==============================] - 6s 128ms/step - loss: 0.6939 - acc: 0.5014 - val_loss: 0.6926 - val_acc: 0.5312\n",
            "Epoch 117/200\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 0.6927 - acc: 0.5073 - val_loss: 0.6923 - val_acc: 0.5160\n",
            "Epoch 118/200\n",
            "45/45 [==============================] - 5s 101ms/step - loss: 0.6941 - acc: 0.5028 - val_loss: 0.6925 - val_acc: 0.5160\n",
            "Epoch 119/200\n",
            "45/45 [==============================] - 6s 139ms/step - loss: 0.6932 - acc: 0.5132 - val_loss: 0.6931 - val_acc: 0.4854\n",
            "Epoch 120/200\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 0.6927 - acc: 0.5028 - val_loss: 0.6926 - val_acc: 0.5132\n",
            "Epoch 121/200\n",
            "45/45 [==============================] - 6s 127ms/step - loss: 0.6931 - acc: 0.5108 - val_loss: 0.6926 - val_acc: 0.5146\n",
            "Epoch 122/200\n",
            "45/45 [==============================] - 4s 100ms/step - loss: 0.6937 - acc: 0.5010 - val_loss: 0.6924 - val_acc: 0.5146\n",
            "Epoch 123/200\n",
            "45/45 [==============================] - 5s 109ms/step - loss: 0.6940 - acc: 0.5059 - val_loss: 0.6925 - val_acc: 0.5146\n",
            "Epoch 124/200\n",
            "45/45 [==============================] - 5s 113ms/step - loss: 0.6932 - acc: 0.5125 - val_loss: 0.6913 - val_acc: 0.5340\n",
            "Epoch 125/200\n",
            "45/45 [==============================] - 4s 99ms/step - loss: 0.6935 - acc: 0.5073 - val_loss: 0.6911 - val_acc: 0.5354\n",
            "Epoch 126/200\n",
            "45/45 [==============================] - 5s 121ms/step - loss: 0.6932 - acc: 0.5181 - val_loss: 0.6918 - val_acc: 0.5326\n",
            "Epoch 127/200\n",
            "45/45 [==============================] - 5s 100ms/step - loss: 0.6930 - acc: 0.5111 - val_loss: 0.6917 - val_acc: 0.5381\n",
            "Epoch 128/200\n",
            "45/45 [==============================] - 4s 98ms/step - loss: 0.6926 - acc: 0.5073 - val_loss: 0.6912 - val_acc: 0.5340\n",
            "Epoch 129/200\n",
            "45/45 [==============================] - 6s 123ms/step - loss: 0.6927 - acc: 0.5226 - val_loss: 0.6911 - val_acc: 0.5354\n",
            "Epoch 130/200\n",
            "45/45 [==============================] - 5s 112ms/step - loss: 0.6934 - acc: 0.5149 - val_loss: 0.6913 - val_acc: 0.5326\n",
            "Epoch 131/200\n",
            "45/45 [==============================] - 6s 132ms/step - loss: 0.6928 - acc: 0.5215 - val_loss: 0.6916 - val_acc: 0.5284\n",
            "Epoch 132/200\n",
            "45/45 [==============================] - 5s 104ms/step - loss: 0.6936 - acc: 0.5160 - val_loss: 0.6924 - val_acc: 0.5243\n",
            "Epoch 133/200\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 0.6931 - acc: 0.5101 - val_loss: 0.6922 - val_acc: 0.5312\n",
            "Epoch 134/200\n",
            "45/45 [==============================] - 5s 117ms/step - loss: 0.6930 - acc: 0.5066 - val_loss: 0.6917 - val_acc: 0.5312\n",
            "Epoch 135/200\n",
            "45/45 [==============================] - 4s 100ms/step - loss: 0.6920 - acc: 0.5188 - val_loss: 0.6912 - val_acc: 0.5284\n",
            "Epoch 136/200\n",
            "45/45 [==============================] - 6s 128ms/step - loss: 0.6935 - acc: 0.5087 - val_loss: 0.6917 - val_acc: 0.5326\n",
            "Epoch 137/200\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 0.6932 - acc: 0.5066 - val_loss: 0.6909 - val_acc: 0.5409\n",
            "Epoch 138/200\n",
            "45/45 [==============================] - 4s 99ms/step - loss: 0.6929 - acc: 0.5146 - val_loss: 0.6908 - val_acc: 0.5437\n",
            "Epoch 139/200\n",
            "45/45 [==============================] - 5s 122ms/step - loss: 0.6927 - acc: 0.5149 - val_loss: 0.6910 - val_acc: 0.5451\n",
            "Epoch 140/200\n",
            "45/45 [==============================] - 4s 99ms/step - loss: 0.6935 - acc: 0.5090 - val_loss: 0.6921 - val_acc: 0.5187\n",
            "Epoch 141/200\n",
            "45/45 [==============================] - 5s 120ms/step - loss: 0.6935 - acc: 0.5122 - val_loss: 0.6921 - val_acc: 0.5201\n",
            "Epoch 142/200\n",
            "45/45 [==============================] - 5s 101ms/step - loss: 0.6944 - acc: 0.4913 - val_loss: 0.6922 - val_acc: 0.5160\n",
            "Epoch 143/200\n",
            "45/45 [==============================] - 4s 99ms/step - loss: 0.6927 - acc: 0.5194 - val_loss: 0.6924 - val_acc: 0.5173\n",
            "Epoch 144/200\n",
            "45/45 [==============================] - 5s 121ms/step - loss: 0.6933 - acc: 0.5076 - val_loss: 0.6918 - val_acc: 0.5257\n",
            "Epoch 145/200\n",
            "45/45 [==============================] - 4s 98ms/step - loss: 0.6925 - acc: 0.5149 - val_loss: 0.6903 - val_acc: 0.5465\n",
            "Epoch 146/200\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 0.6935 - acc: 0.5153 - val_loss: 0.6921 - val_acc: 0.5312\n",
            "Epoch 147/200\n",
            "45/45 [==============================] - 5s 115ms/step - loss: 0.6931 - acc: 0.5094 - val_loss: 0.6920 - val_acc: 0.5257\n",
            "Epoch 148/200\n",
            "45/45 [==============================] - 5s 103ms/step - loss: 0.6937 - acc: 0.5108 - val_loss: 0.6920 - val_acc: 0.5312\n",
            "Epoch 149/200\n",
            "45/45 [==============================] - 5s 119ms/step - loss: 0.6934 - acc: 0.5170 - val_loss: 0.6915 - val_acc: 0.5381\n",
            "Epoch 150/200\n",
            "45/45 [==============================] - 4s 100ms/step - loss: 0.6931 - acc: 0.5045 - val_loss: 0.6919 - val_acc: 0.5312\n",
            "Epoch 151/200\n",
            "45/45 [==============================] - 4s 100ms/step - loss: 0.6934 - acc: 0.5153 - val_loss: 0.6913 - val_acc: 0.5381\n",
            "Epoch 152/200\n",
            "45/45 [==============================] - 5s 122ms/step - loss: 0.6931 - acc: 0.5132 - val_loss: 0.6907 - val_acc: 0.5465\n",
            "Epoch 153/200\n",
            "45/45 [==============================] - 4s 100ms/step - loss: 0.6927 - acc: 0.5191 - val_loss: 0.6922 - val_acc: 0.5270\n",
            "Epoch 154/200\n",
            "45/45 [==============================] - 6s 133ms/step - loss: 0.6926 - acc: 0.5000 - val_loss: 0.6920 - val_acc: 0.5298\n",
            "Epoch 155/200\n",
            "45/45 [==============================] - 4s 99ms/step - loss: 0.6930 - acc: 0.5083 - val_loss: 0.6910 - val_acc: 0.5465\n",
            "Epoch 156/200\n",
            "45/45 [==============================] - 4s 98ms/step - loss: 0.6934 - acc: 0.5201 - val_loss: 0.6910 - val_acc: 0.5423\n",
            "Epoch 157/200\n",
            "45/45 [==============================] - 5s 122ms/step - loss: 0.6924 - acc: 0.5194 - val_loss: 0.6907 - val_acc: 0.5423\n",
            "Epoch 158/200\n",
            "45/45 [==============================] - 4s 99ms/step - loss: 0.6927 - acc: 0.5181 - val_loss: 0.6902 - val_acc: 0.5465\n",
            "Epoch 159/200\n",
            "45/45 [==============================] - 6s 127ms/step - loss: 0.6929 - acc: 0.5156 - val_loss: 0.6889 - val_acc: 0.5451\n",
            "Epoch 160/200\n",
            "45/45 [==============================] - 4s 100ms/step - loss: 0.6928 - acc: 0.5167 - val_loss: 0.6906 - val_acc: 0.5340\n",
            "Epoch 161/200\n",
            "45/45 [==============================] - 4s 100ms/step - loss: 0.6921 - acc: 0.5184 - val_loss: 0.6896 - val_acc: 0.5437\n",
            "Epoch 162/200\n",
            "45/45 [==============================] - 5s 120ms/step - loss: 0.6925 - acc: 0.5170 - val_loss: 0.6907 - val_acc: 0.5381\n",
            "Epoch 163/200\n",
            "45/45 [==============================] - 4s 99ms/step - loss: 0.6935 - acc: 0.5146 - val_loss: 0.6903 - val_acc: 0.5409\n",
            "Epoch 164/200\n",
            "45/45 [==============================] - 6s 139ms/step - loss: 0.6918 - acc: 0.5142 - val_loss: 0.6917 - val_acc: 0.5243\n",
            "Epoch 165/200\n",
            "45/45 [==============================] - 5s 110ms/step - loss: 0.6933 - acc: 0.5094 - val_loss: 0.6911 - val_acc: 0.5312\n",
            "Epoch 166/200\n",
            "45/45 [==============================] - 4s 99ms/step - loss: 0.6935 - acc: 0.5038 - val_loss: 0.6920 - val_acc: 0.5132\n",
            "Epoch 167/200\n",
            "45/45 [==============================] - 6s 123ms/step - loss: 0.6935 - acc: 0.5097 - val_loss: 0.6920 - val_acc: 0.5284\n",
            "Epoch 168/200\n",
            "45/45 [==============================] - 5s 109ms/step - loss: 0.6924 - acc: 0.5083 - val_loss: 0.6918 - val_acc: 0.5270\n",
            "Epoch 169/200\n",
            "45/45 [==============================] - 6s 144ms/step - loss: 0.6926 - acc: 0.5240 - val_loss: 0.6919 - val_acc: 0.5257\n",
            "Epoch 170/200\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.6933 - acc: 0.5125 - val_loss: 0.6922 - val_acc: 0.5146\n",
            "Epoch 171/200\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.6933 - acc: 0.5142 - val_loss: 0.6925 - val_acc: 0.5173\n",
            "Epoch 172/200\n",
            "45/45 [==============================] - 5s 122ms/step - loss: 0.6931 - acc: 0.4941 - val_loss: 0.6922 - val_acc: 0.5215\n",
            "Epoch 173/200\n",
            "45/45 [==============================] - 5s 101ms/step - loss: 0.6929 - acc: 0.5253 - val_loss: 0.6919 - val_acc: 0.5243\n",
            "Epoch 174/200\n",
            "45/45 [==============================] - 5s 123ms/step - loss: 0.6926 - acc: 0.5059 - val_loss: 0.6919 - val_acc: 0.5243\n",
            "Epoch 175/200\n",
            "45/45 [==============================] - 4s 100ms/step - loss: 0.6932 - acc: 0.5080 - val_loss: 0.6917 - val_acc: 0.5284\n",
            "Epoch 176/200\n",
            "45/45 [==============================] - 4s 100ms/step - loss: 0.6929 - acc: 0.5142 - val_loss: 0.6921 - val_acc: 0.5173\n",
            "Epoch 177/200\n",
            "45/45 [==============================] - 5s 123ms/step - loss: 0.6928 - acc: 0.5184 - val_loss: 0.6921 - val_acc: 0.5229\n",
            "Epoch 178/200\n",
            "45/45 [==============================] - 4s 100ms/step - loss: 0.6926 - acc: 0.5219 - val_loss: 0.6924 - val_acc: 0.5104\n",
            "Epoch 179/200\n",
            "45/45 [==============================] - 5s 119ms/step - loss: 0.6923 - acc: 0.5069 - val_loss: 0.6910 - val_acc: 0.5340\n",
            "Epoch 180/200\n",
            "45/45 [==============================] - 6s 129ms/step - loss: 0.6925 - acc: 0.5306 - val_loss: 0.6943 - val_acc: 0.5104\n",
            "Epoch 181/200\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 0.6945 - acc: 0.4920 - val_loss: 0.6927 - val_acc: 0.5146\n",
            "Epoch 182/200\n",
            "45/45 [==============================] - 5s 122ms/step - loss: 0.6941 - acc: 0.4958 - val_loss: 0.6927 - val_acc: 0.5187\n",
            "Epoch 183/200\n",
            "45/45 [==============================] - 5s 100ms/step - loss: 0.6932 - acc: 0.5066 - val_loss: 0.6923 - val_acc: 0.5270\n",
            "Epoch 184/200\n",
            "45/45 [==============================] - 5s 100ms/step - loss: 0.6932 - acc: 0.5080 - val_loss: 0.6926 - val_acc: 0.5284\n",
            "Epoch 185/200\n",
            "45/45 [==============================] - 5s 121ms/step - loss: 0.6938 - acc: 0.5017 - val_loss: 0.6930 - val_acc: 0.4979\n",
            "Epoch 186/200\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 0.6941 - acc: 0.4969 - val_loss: 0.6930 - val_acc: 0.5007\n",
            "Epoch 187/200\n",
            "45/45 [==============================] - 6s 127ms/step - loss: 0.6933 - acc: 0.5052 - val_loss: 0.6930 - val_acc: 0.5007\n",
            "Epoch 188/200\n",
            "45/45 [==============================] - 6s 122ms/step - loss: 0.6927 - acc: 0.5118 - val_loss: 0.6924 - val_acc: 0.5173\n",
            "Epoch 189/200\n",
            "45/45 [==============================] - 5s 117ms/step - loss: 0.6933 - acc: 0.5028 - val_loss: 0.6925 - val_acc: 0.5146\n",
            "Epoch 190/200\n",
            "45/45 [==============================] - 6s 136ms/step - loss: 0.6932 - acc: 0.5083 - val_loss: 0.6926 - val_acc: 0.5160\n",
            "Epoch 191/200\n",
            "45/45 [==============================] - 5s 112ms/step - loss: 0.6936 - acc: 0.5010 - val_loss: 0.6925 - val_acc: 0.5160\n",
            "Epoch 192/200\n",
            "45/45 [==============================] - 6s 128ms/step - loss: 0.6929 - acc: 0.5101 - val_loss: 0.6926 - val_acc: 0.5173\n",
            "Epoch 193/200\n",
            "45/45 [==============================] - 5s 105ms/step - loss: 0.6933 - acc: 0.5149 - val_loss: 0.6924 - val_acc: 0.5146\n",
            "Epoch 194/200\n",
            "45/45 [==============================] - 6s 132ms/step - loss: 0.6932 - acc: 0.5101 - val_loss: 0.6923 - val_acc: 0.5160\n",
            "Epoch 195/200\n",
            "45/45 [==============================] - 5s 104ms/step - loss: 0.6937 - acc: 0.5056 - val_loss: 0.6924 - val_acc: 0.5160\n",
            "Epoch 196/200\n",
            "45/45 [==============================] - 5s 106ms/step - loss: 0.6928 - acc: 0.5163 - val_loss: 0.6925 - val_acc: 0.5160\n",
            "Epoch 197/200\n",
            "45/45 [==============================] - 6s 133ms/step - loss: 0.6926 - acc: 0.5160 - val_loss: 0.6924 - val_acc: 0.5160\n",
            "Epoch 198/200\n",
            "45/45 [==============================] - 5s 102ms/step - loss: 0.6920 - acc: 0.5135 - val_loss: 0.6922 - val_acc: 0.5160\n",
            "Epoch 199/200\n",
            "45/45 [==============================] - 6s 129ms/step - loss: 0.6934 - acc: 0.5156 - val_loss: 0.6922 - val_acc: 0.5104\n",
            "Epoch 200/200\n",
            "45/45 [==============================] - 5s 103ms/step - loss: 0.6934 - acc: 0.5111 - val_loss: 0.6923 - val_acc: 0.5132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rl9gqViQwmHq"
      },
      "source": [
        "\n",
        "## Evaluar el modelo en los datos de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pBvBsP6wmHq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5914f03e-8cbb-428a-ba21-2d79c2aa3a55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 [==============================] - 2s 36ms/step - loss: 0.6928 - acc: 0.5182\n",
            "Test accuracy 0.5181818008422852\n",
            "Test loss 0.6928234696388245\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# carga el modelo\n",
        "model = load_model('RNN.h5')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "\n",
        "# evalua el modelo con evaluate y saca test_loss y test_acc\n",
        "\n",
        "print(\"Test accuracy\", test_acc)\n",
        "print(\"Test loss\", test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# @title SEGUNDO MODELO: LSTM\n",
        "\n",
        "model_LSTM = Sequential()\n",
        "\n",
        "model_LSTM.add(LSTM(64, return_sequences=True, input_shape=input_shape)) # Capa RNN, 32 vectores\n",
        "model_LSTM.add(Dropout(0.5))  # Capa Dropout para prevenir sobreajuste\n",
        "model_LSTM.add(LSTM(32)) # Capa RNN, 32 vectores\n",
        "model_LSTM.add(Dropout(0.5))\n",
        "model_LSTM.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "kysSCE-Ws55z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ENTRENAMIENTO\n",
        "\n",
        "## CREAMOS MODELO:\n",
        "# compila el modelo eligiendo optimizer, loss y metrics\n",
        "model_LSTM.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
      ],
      "metadata": {
        "id": "ld21MS2DtLyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## ENTRENAMOS:\n",
        "\n",
        "# Define las épocas y batch_size\n",
        "epochs = 200\n",
        "batch_size = 64\n",
        "\n",
        "# entrena el modelo y almacena el entrenamiento en la variable history\n",
        "history = model_LSTM.fit(x_train, y_train,\n",
        "                  epochs= epochs,\n",
        "                  batch_size=batch_size,\n",
        "                  validation_split=0.2)\n",
        "\n",
        "\n",
        "# guarda el modelo en .h5\n",
        "model_LSTM.save('LSTM.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AOqHF9StTZ2",
        "outputId": "3b19b92e-895e-4739-9bd6-31ba302ba8fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "45/45 [==============================] - 5s 53ms/step - loss: 0.6926 - acc: 0.5260 - val_loss: 0.6923 - val_acc: 0.5215\n",
            "Epoch 2/200\n",
            "45/45 [==============================] - 1s 31ms/step - loss: 0.6934 - acc: 0.5021 - val_loss: 0.6918 - val_acc: 0.5243\n",
            "Epoch 3/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6933 - acc: 0.5083 - val_loss: 0.6923 - val_acc: 0.5201\n",
            "Epoch 4/200\n",
            "45/45 [==============================] - 2s 45ms/step - loss: 0.6949 - acc: 0.5052 - val_loss: 0.6923 - val_acc: 0.5201\n",
            "Epoch 5/200\n",
            "45/45 [==============================] - 2s 38ms/step - loss: 0.6930 - acc: 0.5260 - val_loss: 0.6932 - val_acc: 0.5187\n",
            "Epoch 6/200\n",
            "45/45 [==============================] - 1s 31ms/step - loss: 0.6936 - acc: 0.5163 - val_loss: 0.6925 - val_acc: 0.5243\n",
            "Epoch 7/200\n",
            "45/45 [==============================] - 2s 35ms/step - loss: 0.6929 - acc: 0.5267 - val_loss: 0.6911 - val_acc: 0.5298\n",
            "Epoch 8/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6924 - acc: 0.5260 - val_loss: 0.6925 - val_acc: 0.5076\n",
            "Epoch 9/200\n",
            "45/45 [==============================] - 1s 31ms/step - loss: 0.6941 - acc: 0.5135 - val_loss: 0.6909 - val_acc: 0.5284\n",
            "Epoch 10/200\n",
            "45/45 [==============================] - 2s 35ms/step - loss: 0.6923 - acc: 0.5181 - val_loss: 0.6910 - val_acc: 0.5298\n",
            "Epoch 11/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6956 - acc: 0.5212 - val_loss: 0.6946 - val_acc: 0.5090\n",
            "Epoch 12/200\n",
            "45/45 [==============================] - 2s 39ms/step - loss: 0.6914 - acc: 0.5316 - val_loss: 0.6882 - val_acc: 0.5298\n",
            "Epoch 13/200\n",
            "45/45 [==============================] - 2s 43ms/step - loss: 0.6995 - acc: 0.5292 - val_loss: 0.6951 - val_acc: 0.4854\n",
            "Epoch 14/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6934 - acc: 0.5156 - val_loss: 0.6917 - val_acc: 0.5284\n",
            "Epoch 15/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6914 - acc: 0.5174 - val_loss: 0.6896 - val_acc: 0.5465\n",
            "Epoch 16/200\n",
            "45/45 [==============================] - 1s 31ms/step - loss: 0.6866 - acc: 0.5455 - val_loss: 0.6827 - val_acc: 0.5659\n",
            "Epoch 17/200\n",
            "45/45 [==============================] - 1s 31ms/step - loss: 0.7073 - acc: 0.5260 - val_loss: 0.6928 - val_acc: 0.5160\n",
            "Epoch 18/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6956 - acc: 0.4979 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 19/200\n",
            "45/45 [==============================] - 1s 31ms/step - loss: 0.6950 - acc: 0.4938 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 20/200\n",
            "45/45 [==============================] - 2s 36ms/step - loss: 0.6954 - acc: 0.4906 - val_loss: 0.6928 - val_acc: 0.5160\n",
            "Epoch 21/200\n",
            "45/45 [==============================] - 2s 44ms/step - loss: 0.6936 - acc: 0.5042 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 22/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6938 - acc: 0.4979 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 23/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6936 - acc: 0.5024 - val_loss: 0.6928 - val_acc: 0.5160\n",
            "Epoch 24/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6927 - acc: 0.5253 - val_loss: 0.6928 - val_acc: 0.5160\n",
            "Epoch 25/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6932 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 26/200\n",
            "45/45 [==============================] - 1s 31ms/step - loss: 0.6936 - acc: 0.5031 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 27/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6928 - acc: 0.5212 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 28/200\n",
            "45/45 [==============================] - 1s 33ms/step - loss: 0.6941 - acc: 0.5035 - val_loss: 0.6926 - val_acc: 0.5160\n",
            "Epoch 29/200\n",
            "45/45 [==============================] - 2s 43ms/step - loss: 0.6938 - acc: 0.5052 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 30/200\n",
            "45/45 [==============================] - 2s 36ms/step - loss: 0.6931 - acc: 0.5177 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 31/200\n",
            "45/45 [==============================] - 1s 31ms/step - loss: 0.6932 - acc: 0.5090 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 32/200\n",
            "45/45 [==============================] - 1s 31ms/step - loss: 0.6920 - acc: 0.5181 - val_loss: 0.6928 - val_acc: 0.5160\n",
            "Epoch 33/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6937 - acc: 0.5104 - val_loss: 0.6926 - val_acc: 0.5160\n",
            "Epoch 34/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6931 - acc: 0.5059 - val_loss: 0.6928 - val_acc: 0.5160\n",
            "Epoch 35/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6933 - acc: 0.5128 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 36/200\n",
            "45/45 [==============================] - 1s 31ms/step - loss: 0.6928 - acc: 0.5139 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 37/200\n",
            "45/45 [==============================] - 2s 42ms/step - loss: 0.6929 - acc: 0.5156 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 38/200\n",
            "45/45 [==============================] - 2s 38ms/step - loss: 0.6933 - acc: 0.5028 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 39/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6933 - acc: 0.5097 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 40/200\n",
            "45/45 [==============================] - 2s 35ms/step - loss: 0.6936 - acc: 0.5101 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 41/200\n",
            "45/45 [==============================] - 2s 35ms/step - loss: 0.6932 - acc: 0.5104 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 42/200\n",
            "45/45 [==============================] - 2s 45ms/step - loss: 0.6930 - acc: 0.5111 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 43/200\n",
            "45/45 [==============================] - 2s 34ms/step - loss: 0.6931 - acc: 0.5111 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 44/200\n",
            "45/45 [==============================] - 2s 34ms/step - loss: 0.6930 - acc: 0.5125 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 45/200\n",
            "45/45 [==============================] - 2s 44ms/step - loss: 0.6927 - acc: 0.5135 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 46/200\n",
            "45/45 [==============================] - 2s 34ms/step - loss: 0.6930 - acc: 0.5111 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 47/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6930 - acc: 0.5111 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 48/200\n",
            "45/45 [==============================] - 1s 33ms/step - loss: 0.6930 - acc: 0.5104 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 49/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6929 - acc: 0.5122 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 50/200\n",
            "45/45 [==============================] - 1s 33ms/step - loss: 0.6930 - acc: 0.5111 - val_loss: 0.6926 - val_acc: 0.5160\n",
            "Epoch 51/200\n",
            "45/45 [==============================] - 2s 42ms/step - loss: 0.6932 - acc: 0.5149 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 52/200\n",
            "45/45 [==============================] - 2s 45ms/step - loss: 0.6929 - acc: 0.5097 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 53/200\n",
            "45/45 [==============================] - 2s 43ms/step - loss: 0.6933 - acc: 0.5076 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 54/200\n",
            "45/45 [==============================] - 1s 33ms/step - loss: 0.6932 - acc: 0.5115 - val_loss: 0.6926 - val_acc: 0.5160\n",
            "Epoch 55/200\n",
            "45/45 [==============================] - 1s 33ms/step - loss: 0.6930 - acc: 0.5111 - val_loss: 0.6926 - val_acc: 0.5160\n",
            "Epoch 56/200\n",
            "45/45 [==============================] - 2s 36ms/step - loss: 0.6925 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 57/200\n",
            "45/45 [==============================] - 2s 35ms/step - loss: 0.6933 - acc: 0.5028 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 58/200\n",
            "45/45 [==============================] - 2s 35ms/step - loss: 0.6931 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 59/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6931 - acc: 0.5122 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 60/200\n",
            "45/45 [==============================] - 2s 42ms/step - loss: 0.6928 - acc: 0.5163 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 61/200\n",
            "45/45 [==============================] - 2s 40ms/step - loss: 0.6930 - acc: 0.5125 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 62/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6932 - acc: 0.5066 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 63/200\n",
            "45/45 [==============================] - 2s 35ms/step - loss: 0.6928 - acc: 0.5128 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 64/200\n",
            "45/45 [==============================] - 1s 33ms/step - loss: 0.6930 - acc: 0.5094 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 65/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6928 - acc: 0.5156 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 66/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6926 - acc: 0.5115 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 67/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 68/200\n",
            "45/45 [==============================] - 2s 42ms/step - loss: 0.6928 - acc: 0.5097 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 69/200\n",
            "45/45 [==============================] - 2s 39ms/step - loss: 0.6928 - acc: 0.5132 - val_loss: 0.6928 - val_acc: 0.5160\n",
            "Epoch 70/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6930 - acc: 0.5139 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 71/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6934 - acc: 0.4983 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 72/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6931 - acc: 0.5128 - val_loss: 0.6926 - val_acc: 0.5160\n",
            "Epoch 73/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6929 - acc: 0.5111 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 74/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6927 - acc: 0.5076 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 75/200\n",
            "45/45 [==============================] - 1s 33ms/step - loss: 0.6930 - acc: 0.5128 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 76/200\n",
            "45/45 [==============================] - 2s 41ms/step - loss: 0.6931 - acc: 0.5111 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 77/200\n",
            "45/45 [==============================] - 2s 42ms/step - loss: 0.6930 - acc: 0.5118 - val_loss: 0.6926 - val_acc: 0.5160\n",
            "Epoch 78/200\n",
            "45/45 [==============================] - 1s 33ms/step - loss: 0.6930 - acc: 0.5115 - val_loss: 0.6926 - val_acc: 0.5160\n",
            "Epoch 79/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6930 - acc: 0.5125 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 80/200\n",
            "45/45 [==============================] - 2s 39ms/step - loss: 0.6928 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 81/200\n",
            "45/45 [==============================] - 2s 43ms/step - loss: 0.6930 - acc: 0.5118 - val_loss: 0.6926 - val_acc: 0.5160\n",
            "Epoch 82/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6931 - acc: 0.5108 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 83/200\n",
            "45/45 [==============================] - 1s 33ms/step - loss: 0.6930 - acc: 0.5104 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 84/200\n",
            "45/45 [==============================] - 2s 45ms/step - loss: 0.6930 - acc: 0.5115 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 85/200\n",
            "45/45 [==============================] - 2s 34ms/step - loss: 0.6929 - acc: 0.5111 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 86/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6928 - acc: 0.5125 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 87/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6929 - acc: 0.5139 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 88/200\n",
            "45/45 [==============================] - 1s 31ms/step - loss: 0.6928 - acc: 0.5128 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 89/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6932 - acc: 0.5094 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 90/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6931 - acc: 0.5108 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 91/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6929 - acc: 0.5111 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 92/200\n",
            "45/45 [==============================] - 2s 43ms/step - loss: 0.6930 - acc: 0.5097 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 93/200\n",
            "45/45 [==============================] - 2s 37ms/step - loss: 0.6931 - acc: 0.5122 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 94/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6928 - acc: 0.5132 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 95/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6928 - acc: 0.5156 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 96/200\n",
            "45/45 [==============================] - 1s 31ms/step - loss: 0.6929 - acc: 0.5104 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 97/200\n",
            "45/45 [==============================] - 2s 35ms/step - loss: 0.6928 - acc: 0.5125 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 98/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6930 - acc: 0.5104 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 99/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6929 - acc: 0.5111 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 100/200\n",
            "45/45 [==============================] - 2s 39ms/step - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 101/200\n",
            "45/45 [==============================] - 2s 40ms/step - loss: 0.6930 - acc: 0.5115 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 102/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6928 - acc: 0.5132 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 103/200\n",
            "45/45 [==============================] - 1s 31ms/step - loss: 0.6929 - acc: 0.5108 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 104/200\n",
            "45/45 [==============================] - 1s 31ms/step - loss: 0.6930 - acc: 0.5104 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 105/200\n",
            "45/45 [==============================] - 2s 36ms/step - loss: 0.6931 - acc: 0.5125 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 106/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6928 - acc: 0.5122 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 107/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6930 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 108/200\n",
            "45/45 [==============================] - 2s 36ms/step - loss: 0.6930 - acc: 0.5118 - val_loss: 0.6926 - val_acc: 0.5160\n",
            "Epoch 109/200\n",
            "45/45 [==============================] - 2s 43ms/step - loss: 0.6928 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 110/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6930 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 111/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6929 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 112/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6929 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 113/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6929 - acc: 0.5115 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 114/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6930 - acc: 0.5122 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 115/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6929 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 116/200\n",
            "45/45 [==============================] - 1s 31ms/step - loss: 0.6929 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 117/200\n",
            "45/45 [==============================] - 2s 43ms/step - loss: 0.6929 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 118/200\n",
            "45/45 [==============================] - 2s 37ms/step - loss: 0.6927 - acc: 0.5115 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 119/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6930 - acc: 0.5115 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 120/200\n",
            "45/45 [==============================] - 1s 33ms/step - loss: 0.6929 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 121/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6928 - acc: 0.5115 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 122/200\n",
            "45/45 [==============================] - 2s 36ms/step - loss: 0.6930 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 123/200\n",
            "45/45 [==============================] - 1s 31ms/step - loss: 0.6927 - acc: 0.5111 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 124/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6930 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 125/200\n",
            "45/45 [==============================] - 2s 41ms/step - loss: 0.6929 - acc: 0.5108 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 126/200\n",
            "45/45 [==============================] - 2s 40ms/step - loss: 0.6929 - acc: 0.5128 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 127/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6930 - acc: 0.5115 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 128/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6928 - acc: 0.5122 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 129/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6928 - acc: 0.5111 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 130/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6930 - acc: 0.5125 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 131/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6934 - acc: 0.5122 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 132/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6929 - acc: 0.5125 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 133/200\n",
            "45/45 [==============================] - 2s 39ms/step - loss: 0.6930 - acc: 0.5115 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 134/200\n",
            "45/45 [==============================] - 2s 42ms/step - loss: 0.6930 - acc: 0.5115 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 135/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6929 - acc: 0.5122 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 136/200\n",
            "45/45 [==============================] - 1s 33ms/step - loss: 0.6929 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 137/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6929 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 138/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6929 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 139/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6929 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 140/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6928 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 141/200\n",
            "45/45 [==============================] - 2s 39ms/step - loss: 0.6929 - acc: 0.5115 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 142/200\n",
            "45/45 [==============================] - 2s 44ms/step - loss: 0.6930 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 143/200\n",
            "45/45 [==============================] - 1s 33ms/step - loss: 0.6928 - acc: 0.5122 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 144/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6930 - acc: 0.5115 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 145/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6930 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 146/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6928 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 147/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6929 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 148/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6928 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 149/200\n",
            "45/45 [==============================] - 2s 36ms/step - loss: 0.6930 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 150/200\n",
            "45/45 [==============================] - 2s 44ms/step - loss: 0.6930 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 151/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6929 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 152/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6929 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 153/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6930 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 154/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6928 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 155/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6930 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 156/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6929 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 157/200\n",
            "45/45 [==============================] - 2s 36ms/step - loss: 0.6929 - acc: 0.5115 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 158/200\n",
            "45/45 [==============================] - 2s 43ms/step - loss: 0.6930 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 159/200\n",
            "45/45 [==============================] - 2s 35ms/step - loss: 0.6930 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 160/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6928 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 161/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6931 - acc: 0.5115 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 162/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6928 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 163/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6929 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 164/200\n",
            "45/45 [==============================] - 2s 36ms/step - loss: 0.6928 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 165/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6930 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 166/200\n",
            "45/45 [==============================] - 2s 43ms/step - loss: 0.6929 - acc: 0.5115 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 167/200\n",
            "45/45 [==============================] - 2s 40ms/step - loss: 0.6928 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 168/200\n",
            "45/45 [==============================] - 2s 35ms/step - loss: 0.6929 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 169/200\n",
            "45/45 [==============================] - 1s 33ms/step - loss: 0.6929 - acc: 0.5125 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 170/200\n",
            "45/45 [==============================] - 1s 31ms/step - loss: 0.6929 - acc: 0.5128 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 171/200\n",
            "45/45 [==============================] - 1s 33ms/step - loss: 0.6930 - acc: 0.5122 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 172/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6929 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 173/200\n",
            "45/45 [==============================] - 2s 35ms/step - loss: 0.6929 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 174/200\n",
            "45/45 [==============================] - 2s 46ms/step - loss: 0.6929 - acc: 0.5122 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 175/200\n",
            "45/45 [==============================] - 2s 33ms/step - loss: 0.6929 - acc: 0.5115 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 176/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6929 - acc: 0.5135 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 177/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6930 - acc: 0.5122 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 178/200\n",
            "45/45 [==============================] - 1s 33ms/step - loss: 0.6929 - acc: 0.5097 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 179/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6929 - acc: 0.5122 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 180/200\n",
            "45/45 [==============================] - 1s 33ms/step - loss: 0.6929 - acc: 0.5115 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 181/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6930 - acc: 0.5122 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 182/200\n",
            "45/45 [==============================] - 2s 45ms/step - loss: 0.6928 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 183/200\n",
            "45/45 [==============================] - 2s 34ms/step - loss: 0.6930 - acc: 0.5115 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 184/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6928 - acc: 0.5115 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 185/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6930 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 186/200\n",
            "45/45 [==============================] - 1s 33ms/step - loss: 0.6929 - acc: 0.5122 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 187/200\n",
            "45/45 [==============================] - 1s 33ms/step - loss: 0.6929 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 188/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6929 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 189/200\n",
            "45/45 [==============================] - 1s 33ms/step - loss: 0.6929 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 190/200\n",
            "45/45 [==============================] - 2s 46ms/step - loss: 0.6929 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 191/200\n",
            "45/45 [==============================] - 2s 35ms/step - loss: 0.6928 - acc: 0.5128 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 192/200\n",
            "45/45 [==============================] - 2s 35ms/step - loss: 0.6928 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 193/200\n",
            "45/45 [==============================] - 1s 33ms/step - loss: 0.6930 - acc: 0.5083 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 194/200\n",
            "45/45 [==============================] - 1s 33ms/step - loss: 0.6930 - acc: 0.5101 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 195/200\n",
            "45/45 [==============================] - 2s 36ms/step - loss: 0.6929 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 196/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6929 - acc: 0.5108 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 197/200\n",
            "45/45 [==============================] - 2s 35ms/step - loss: 0.6929 - acc: 0.5128 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 198/200\n",
            "45/45 [==============================] - 2s 45ms/step - loss: 0.6929 - acc: 0.5104 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 199/200\n",
            "45/45 [==============================] - 1s 32ms/step - loss: 0.6929 - acc: 0.5132 - val_loss: 0.6927 - val_acc: 0.5160\n",
            "Epoch 200/200\n",
            "45/45 [==============================] - 1s 33ms/step - loss: 0.6928 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## EVALUAMOS:\n",
        "\n",
        "# carga el modelo\n",
        "model = load_model('LSTM.h5')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "\n",
        "# evalua el modelo con evaluate y saca test_loss y test_acc\n",
        "\n",
        "print(\"Test accuracy\", test_acc)\n",
        "print(\"Test loss\", test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-7QWUzbtdwR",
        "outputId": "5969dfdb-4b25-4fc2-9182-c98a20739d9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 [==============================] - 1s 16ms/step - loss: 0.6927 - acc: 0.5159\n",
            "Test accuracy 0.5159090757369995\n",
            "Test loss 0.6926639676094055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# @title TERCER MODELO: GRU\n",
        "\n",
        "model_GRU = Sequential()\n",
        "\n",
        "model_GRU.add(GRU(64)) # Capa RNN, 32 vectores\n",
        "model_GRU.add(Dropout(0.5))\n",
        "model_GRU.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "rOYJ4V4Xs98e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ENTRENAMIENTO\n",
        "\n",
        "## CREAMOS MODELO:\n",
        "# compila el modelo eligiendo optimizer, loss y metrics\n",
        "model_GRU.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
      ],
      "metadata": {
        "id": "WPv5DEdftOZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## ENTRENAMOS:\n",
        "\n",
        "# Define las épocas y batch_size\n",
        "epochs = 200\n",
        "batch_size = 64\n",
        "\n",
        "# entrena el modelo y almacena el entrenamiento en la variable history\n",
        "history = model_GRU.fit(x_train, y_train,\n",
        "                  epochs= epochs,\n",
        "                  batch_size=batch_size,\n",
        "                  validation_split=0.2)\n",
        "\n",
        "\n",
        "# guarda el modelo en .h5\n",
        "model_GRU.save('GRU.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4non7cbtX-I",
        "outputId": "97991e66-0827-4ef4-bb69-1c2f07853d30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "45/45 [==============================] - 4s 41ms/step - loss: 0.6957 - acc: 0.4983 - val_loss: 0.6923 - val_acc: 0.5326\n",
            "Epoch 2/200\n",
            "45/45 [==============================] - 1s 26ms/step - loss: 0.6947 - acc: 0.5017 - val_loss: 0.6927 - val_acc: 0.5132\n",
            "Epoch 3/200\n",
            "45/45 [==============================] - 1s 20ms/step - loss: 0.6948 - acc: 0.5122 - val_loss: 0.6923 - val_acc: 0.5187\n",
            "Epoch 4/200\n",
            "45/45 [==============================] - 1s 18ms/step - loss: 0.6953 - acc: 0.5031 - val_loss: 0.6916 - val_acc: 0.5215\n",
            "Epoch 5/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6928 - acc: 0.5146 - val_loss: 0.6919 - val_acc: 0.5298\n",
            "Epoch 6/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6929 - acc: 0.5201 - val_loss: 0.6929 - val_acc: 0.5118\n",
            "Epoch 7/200\n",
            "45/45 [==============================] - 1s 19ms/step - loss: 0.6946 - acc: 0.5184 - val_loss: 0.6917 - val_acc: 0.5173\n",
            "Epoch 8/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6924 - acc: 0.5219 - val_loss: 0.6918 - val_acc: 0.5132\n",
            "Epoch 9/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6936 - acc: 0.5198 - val_loss: 0.6926 - val_acc: 0.5049\n",
            "Epoch 10/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6951 - acc: 0.4924 - val_loss: 0.6916 - val_acc: 0.5132\n",
            "Epoch 11/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6921 - acc: 0.5240 - val_loss: 0.6917 - val_acc: 0.5201\n",
            "Epoch 12/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6930 - acc: 0.5208 - val_loss: 0.6918 - val_acc: 0.5160\n",
            "Epoch 13/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6948 - acc: 0.5087 - val_loss: 0.6911 - val_acc: 0.5312\n",
            "Epoch 14/200\n",
            "45/45 [==============================] - 1s 18ms/step - loss: 0.6931 - acc: 0.5201 - val_loss: 0.6917 - val_acc: 0.5132\n",
            "Epoch 15/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6936 - acc: 0.5108 - val_loss: 0.6913 - val_acc: 0.5257\n",
            "Epoch 16/200\n",
            "45/45 [==============================] - 1s 24ms/step - loss: 0.6935 - acc: 0.5125 - val_loss: 0.6912 - val_acc: 0.5326\n",
            "Epoch 17/200\n",
            "45/45 [==============================] - 1s 26ms/step - loss: 0.6923 - acc: 0.5177 - val_loss: 0.6909 - val_acc: 0.5395\n",
            "Epoch 18/200\n",
            "45/45 [==============================] - 1s 19ms/step - loss: 0.6917 - acc: 0.5215 - val_loss: 0.6907 - val_acc: 0.5215\n",
            "Epoch 19/200\n",
            "45/45 [==============================] - 1s 16ms/step - loss: 0.6906 - acc: 0.5271 - val_loss: 0.6904 - val_acc: 0.5173\n",
            "Epoch 20/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6912 - acc: 0.5226 - val_loss: 0.6896 - val_acc: 0.5270\n",
            "Epoch 21/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6917 - acc: 0.5299 - val_loss: 0.6935 - val_acc: 0.5049\n",
            "Epoch 22/200\n",
            "45/45 [==============================] - 1s 18ms/step - loss: 0.6885 - acc: 0.5240 - val_loss: 0.6844 - val_acc: 0.5340\n",
            "Epoch 23/200\n",
            "45/45 [==============================] - 1s 18ms/step - loss: 0.6792 - acc: 0.5813 - val_loss: 0.7732 - val_acc: 0.4840\n",
            "Epoch 24/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.7080 - acc: 0.4906 - val_loss: 0.6921 - val_acc: 0.5160\n",
            "Epoch 25/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6926 - acc: 0.5191 - val_loss: 0.6920 - val_acc: 0.4979\n",
            "Epoch 26/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6921 - acc: 0.5174 - val_loss: 0.6849 - val_acc: 0.5146\n",
            "Epoch 27/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6153 - acc: 0.5924 - val_loss: 0.5540 - val_acc: 0.6782\n",
            "Epoch 28/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.5466 - acc: 0.7017 - val_loss: 0.5595 - val_acc: 0.7060\n",
            "Epoch 29/200\n",
            "45/45 [==============================] - 1s 18ms/step - loss: 0.5909 - acc: 0.6653 - val_loss: 0.7159 - val_acc: 0.4840\n",
            "Epoch 30/200\n",
            "45/45 [==============================] - 1s 19ms/step - loss: 0.7012 - acc: 0.4861 - val_loss: 0.6942 - val_acc: 0.5049\n",
            "Epoch 31/200\n",
            "45/45 [==============================] - 1s 25ms/step - loss: 0.6945 - acc: 0.5049 - val_loss: 0.6919 - val_acc: 0.5201\n",
            "Epoch 32/200\n",
            "45/45 [==============================] - 1s 25ms/step - loss: 0.6935 - acc: 0.5073 - val_loss: 0.6918 - val_acc: 0.4993\n",
            "Epoch 33/200\n",
            "45/45 [==============================] - 1s 19ms/step - loss: 0.6916 - acc: 0.5163 - val_loss: 0.6912 - val_acc: 0.5243\n",
            "Epoch 34/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6927 - acc: 0.5104 - val_loss: 0.6911 - val_acc: 0.5090\n",
            "Epoch 35/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6924 - acc: 0.5059 - val_loss: 0.6906 - val_acc: 0.5173\n",
            "Epoch 36/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6921 - acc: 0.5226 - val_loss: 0.6901 - val_acc: 0.5215\n",
            "Epoch 37/200\n",
            "45/45 [==============================] - 1s 18ms/step - loss: 0.6917 - acc: 0.5128 - val_loss: 0.6900 - val_acc: 0.5132\n",
            "Epoch 38/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6903 - acc: 0.5281 - val_loss: 0.6892 - val_acc: 0.5132\n",
            "Epoch 39/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6899 - acc: 0.5271 - val_loss: 0.6879 - val_acc: 0.5173\n",
            "Epoch 40/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6885 - acc: 0.5299 - val_loss: 0.6851 - val_acc: 0.5284\n",
            "Epoch 41/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6828 - acc: 0.5368 - val_loss: 0.6793 - val_acc: 0.5492\n",
            "Epoch 42/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6703 - acc: 0.5590 - val_loss: 0.6479 - val_acc: 0.5978\n",
            "Epoch 43/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6177 - acc: 0.6642 - val_loss: 0.6524 - val_acc: 0.6630\n",
            "Epoch 44/200\n",
            "45/45 [==============================] - 1s 18ms/step - loss: 0.6629 - acc: 0.6031 - val_loss: 0.6490 - val_acc: 0.5936\n",
            "Epoch 45/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6388 - acc: 0.6236 - val_loss: 0.6186 - val_acc: 0.6352\n",
            "Epoch 46/200\n",
            "45/45 [==============================] - 1s 23ms/step - loss: 0.7426 - acc: 0.6316 - val_loss: 0.8461 - val_acc: 0.5076\n",
            "Epoch 47/200\n",
            "45/45 [==============================] - 1s 25ms/step - loss: 0.6869 - acc: 0.5816 - val_loss: 0.6689 - val_acc: 0.6269\n",
            "Epoch 48/200\n",
            "45/45 [==============================] - 1s 27ms/step - loss: 0.6344 - acc: 0.6639 - val_loss: 0.6029 - val_acc: 0.6796\n",
            "Epoch 49/200\n",
            "45/45 [==============================] - 1s 28ms/step - loss: 0.6877 - acc: 0.5503 - val_loss: 0.7131 - val_acc: 0.4840\n",
            "Epoch 50/200\n",
            "45/45 [==============================] - 1s 31ms/step - loss: 0.7014 - acc: 0.5028 - val_loss: 0.6927 - val_acc: 0.4951\n",
            "Epoch 51/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6934 - acc: 0.5076 - val_loss: 0.6912 - val_acc: 0.5284\n",
            "Epoch 52/200\n",
            "45/45 [==============================] - 1s 19ms/step - loss: 0.6913 - acc: 0.5191 - val_loss: 0.6909 - val_acc: 0.5354\n",
            "Epoch 53/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6918 - acc: 0.5257 - val_loss: 0.6909 - val_acc: 0.5284\n",
            "Epoch 54/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6923 - acc: 0.5142 - val_loss: 0.6908 - val_acc: 0.5160\n",
            "Epoch 55/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6930 - acc: 0.5194 - val_loss: 0.6907 - val_acc: 0.5160\n",
            "Epoch 56/200\n",
            "45/45 [==============================] - 1s 19ms/step - loss: 0.6918 - acc: 0.5167 - val_loss: 0.6906 - val_acc: 0.5243\n",
            "Epoch 57/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6909 - acc: 0.5212 - val_loss: 0.6904 - val_acc: 0.5243\n",
            "Epoch 58/200\n",
            "45/45 [==============================] - 1s 18ms/step - loss: 0.6923 - acc: 0.5101 - val_loss: 0.6901 - val_acc: 0.5243\n",
            "Epoch 59/200\n",
            "45/45 [==============================] - 1s 22ms/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6900 - val_acc: 0.5257\n",
            "Epoch 60/200\n",
            "45/45 [==============================] - 1s 25ms/step - loss: 0.6908 - acc: 0.5153 - val_loss: 0.6898 - val_acc: 0.5229\n",
            "Epoch 61/200\n",
            "45/45 [==============================] - 1s 21ms/step - loss: 0.6904 - acc: 0.5302 - val_loss: 0.6896 - val_acc: 0.5215\n",
            "Epoch 62/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6906 - acc: 0.5236 - val_loss: 0.6894 - val_acc: 0.5368\n",
            "Epoch 63/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6896 - acc: 0.5198 - val_loss: 0.6889 - val_acc: 0.5395\n",
            "Epoch 64/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6881 - acc: 0.5361 - val_loss: 0.6885 - val_acc: 0.5312\n",
            "Epoch 65/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6891 - acc: 0.5260 - val_loss: 0.6875 - val_acc: 0.5298\n",
            "Epoch 66/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6895 - acc: 0.5167 - val_loss: 0.6860 - val_acc: 0.5423\n",
            "Epoch 67/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6847 - acc: 0.5493 - val_loss: 0.6826 - val_acc: 0.5437\n",
            "Epoch 68/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6790 - acc: 0.5500 - val_loss: 0.6680 - val_acc: 0.5631\n",
            "Epoch 69/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6362 - acc: 0.6028 - val_loss: 0.6122 - val_acc: 0.6505\n",
            "Epoch 70/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.7178 - acc: 0.5646 - val_loss: 0.6707 - val_acc: 0.5298\n",
            "Epoch 71/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6719 - acc: 0.5521 - val_loss: 0.6646 - val_acc: 0.5798\n",
            "Epoch 72/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6636 - acc: 0.5778 - val_loss: 0.6499 - val_acc: 0.6117\n",
            "Epoch 73/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6465 - acc: 0.6139 - val_loss: 0.6183 - val_acc: 0.6505\n",
            "Epoch 74/200\n",
            "45/45 [==============================] - 1s 21ms/step - loss: 0.6451 - acc: 0.6458 - val_loss: 1.0591 - val_acc: 0.4896\n",
            "Epoch 75/200\n",
            "45/45 [==============================] - 1s 23ms/step - loss: 0.8009 - acc: 0.4913 - val_loss: 0.6983 - val_acc: 0.4868\n",
            "Epoch 76/200\n",
            "45/45 [==============================] - 1s 22ms/step - loss: 0.6993 - acc: 0.4910 - val_loss: 0.6922 - val_acc: 0.5160\n",
            "Epoch 77/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6953 - acc: 0.5003 - val_loss: 0.6923 - val_acc: 0.5270\n",
            "Epoch 78/200\n",
            "45/45 [==============================] - 1s 18ms/step - loss: 0.6945 - acc: 0.5063 - val_loss: 0.6921 - val_acc: 0.5146\n",
            "Epoch 79/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6948 - acc: 0.5045 - val_loss: 0.6919 - val_acc: 0.5118\n",
            "Epoch 80/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6950 - acc: 0.5003 - val_loss: 0.6919 - val_acc: 0.5146\n",
            "Epoch 81/200\n",
            "45/45 [==============================] - 1s 18ms/step - loss: 0.6926 - acc: 0.5122 - val_loss: 0.6920 - val_acc: 0.5146\n",
            "Epoch 82/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6944 - acc: 0.4924 - val_loss: 0.6919 - val_acc: 0.5243\n",
            "Epoch 83/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6929 - acc: 0.5153 - val_loss: 0.6918 - val_acc: 0.5243\n",
            "Epoch 84/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6935 - acc: 0.5115 - val_loss: 0.6917 - val_acc: 0.5215\n",
            "Epoch 85/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6935 - acc: 0.4972 - val_loss: 0.6917 - val_acc: 0.5187\n",
            "Epoch 86/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6936 - acc: 0.5052 - val_loss: 0.6920 - val_acc: 0.5284\n",
            "Epoch 87/200\n",
            "45/45 [==============================] - 1s 18ms/step - loss: 0.6926 - acc: 0.5135 - val_loss: 0.6914 - val_acc: 0.5160\n",
            "Epoch 88/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6929 - acc: 0.5149 - val_loss: 0.6918 - val_acc: 0.5215\n",
            "Epoch 89/200\n",
            "45/45 [==============================] - 1s 22ms/step - loss: 0.6921 - acc: 0.5069 - val_loss: 0.6915 - val_acc: 0.5215\n",
            "Epoch 90/200\n",
            "45/45 [==============================] - 1s 24ms/step - loss: 0.6930 - acc: 0.5108 - val_loss: 0.6915 - val_acc: 0.5090\n",
            "Epoch 91/200\n",
            "45/45 [==============================] - 1s 24ms/step - loss: 0.6925 - acc: 0.5188 - val_loss: 0.6916 - val_acc: 0.5104\n",
            "Epoch 92/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6921 - acc: 0.5257 - val_loss: 0.6913 - val_acc: 0.5132\n",
            "Epoch 93/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6921 - acc: 0.5146 - val_loss: 0.6911 - val_acc: 0.5104\n",
            "Epoch 94/200\n",
            "45/45 [==============================] - 1s 18ms/step - loss: 0.6926 - acc: 0.5076 - val_loss: 0.6909 - val_acc: 0.5229\n",
            "Epoch 95/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6931 - acc: 0.5031 - val_loss: 0.6907 - val_acc: 0.5118\n",
            "Epoch 96/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6920 - acc: 0.5076 - val_loss: 0.6907 - val_acc: 0.5104\n",
            "Epoch 97/200\n",
            "45/45 [==============================] - 1s 18ms/step - loss: 0.6924 - acc: 0.5049 - val_loss: 0.6906 - val_acc: 0.5160\n",
            "Epoch 98/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6919 - acc: 0.5083 - val_loss: 0.6901 - val_acc: 0.5257\n",
            "Epoch 99/200\n",
            "45/45 [==============================] - 1s 19ms/step - loss: 0.6925 - acc: 0.5056 - val_loss: 0.6905 - val_acc: 0.5146\n",
            "Epoch 100/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6910 - acc: 0.5201 - val_loss: 0.6900 - val_acc: 0.5104\n",
            "Epoch 101/200\n",
            "45/45 [==============================] - 1s 18ms/step - loss: 0.6905 - acc: 0.5236 - val_loss: 0.6896 - val_acc: 0.5160\n",
            "Epoch 102/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6902 - acc: 0.5219 - val_loss: 0.6894 - val_acc: 0.5368\n",
            "Epoch 103/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6909 - acc: 0.5174 - val_loss: 0.6885 - val_acc: 0.5104\n",
            "Epoch 104/200\n",
            "45/45 [==============================] - 1s 22ms/step - loss: 0.6904 - acc: 0.5115 - val_loss: 0.6879 - val_acc: 0.5118\n",
            "Epoch 105/200\n",
            "45/45 [==============================] - 1s 23ms/step - loss: 0.6902 - acc: 0.5139 - val_loss: 0.6877 - val_acc: 0.5257\n",
            "Epoch 106/200\n",
            "45/45 [==============================] - 1s 23ms/step - loss: 0.6881 - acc: 0.5330 - val_loss: 0.6865 - val_acc: 0.5270\n",
            "Epoch 107/200\n",
            "45/45 [==============================] - 1s 18ms/step - loss: 0.6880 - acc: 0.5389 - val_loss: 0.6855 - val_acc: 0.5257\n",
            "Epoch 108/200\n",
            "45/45 [==============================] - 1s 19ms/step - loss: 0.6859 - acc: 0.5295 - val_loss: 0.6844 - val_acc: 0.5173\n",
            "Epoch 109/200\n",
            "45/45 [==============================] - 1s 18ms/step - loss: 0.6852 - acc: 0.5274 - val_loss: 0.6824 - val_acc: 0.5326\n",
            "Epoch 110/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6836 - acc: 0.5483 - val_loss: 0.6796 - val_acc: 0.5423\n",
            "Epoch 111/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6808 - acc: 0.5486 - val_loss: 0.6757 - val_acc: 0.5326\n",
            "Epoch 112/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6745 - acc: 0.5562 - val_loss: 0.6712 - val_acc: 0.6283\n",
            "Epoch 113/200\n",
            "45/45 [==============================] - 1s 19ms/step - loss: 0.6649 - acc: 0.5823 - val_loss: 0.6502 - val_acc: 0.6130\n",
            "Epoch 114/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6121 - acc: 0.6399 - val_loss: 0.5780 - val_acc: 0.6616\n",
            "Epoch 115/200\n",
            "45/45 [==============================] - 1s 18ms/step - loss: 0.5714 - acc: 0.6774 - val_loss: 0.5478 - val_acc: 0.6949\n",
            "Epoch 116/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.5413 - acc: 0.7049 - val_loss: 0.5371 - val_acc: 0.7115\n",
            "Epoch 117/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.5976 - acc: 0.6840 - val_loss: 0.5608 - val_acc: 0.6824\n",
            "Epoch 118/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.5608 - acc: 0.6812 - val_loss: 0.6052 - val_acc: 0.6533\n",
            "Epoch 119/200\n",
            "45/45 [==============================] - 1s 21ms/step - loss: 0.5662 - acc: 0.6833 - val_loss: 0.5403 - val_acc: 0.6949\n",
            "Epoch 120/200\n",
            "45/45 [==============================] - 1s 24ms/step - loss: 0.5558 - acc: 0.6872 - val_loss: 0.5332 - val_acc: 0.6949\n",
            "Epoch 121/200\n",
            "45/45 [==============================] - 1s 23ms/step - loss: 0.8378 - acc: 0.5896 - val_loss: 0.6345 - val_acc: 0.6644\n",
            "Epoch 122/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6297 - acc: 0.6535 - val_loss: 0.5812 - val_acc: 0.7004\n",
            "Epoch 123/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.5569 - acc: 0.7122 - val_loss: 0.5308 - val_acc: 0.7087\n",
            "Epoch 124/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6136 - acc: 0.6451 - val_loss: 0.5781 - val_acc: 0.6671\n",
            "Epoch 125/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.5476 - acc: 0.6969 - val_loss: 0.5096 - val_acc: 0.7032\n",
            "Epoch 126/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.5353 - acc: 0.7247 - val_loss: 0.5315 - val_acc: 0.7157\n",
            "Epoch 127/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.5332 - acc: 0.7153 - val_loss: 0.5329 - val_acc: 0.7337\n",
            "Epoch 128/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.6051 - acc: 0.7010 - val_loss: 0.6011 - val_acc: 0.6893\n",
            "Epoch 129/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.5866 - acc: 0.6788 - val_loss: 0.6231 - val_acc: 0.6824\n",
            "Epoch 130/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.5771 - acc: 0.6767 - val_loss: 0.5420 - val_acc: 0.7129\n",
            "Epoch 131/200\n",
            "45/45 [==============================] - 1s 18ms/step - loss: 0.5865 - acc: 0.6799 - val_loss: 0.5687 - val_acc: 0.6796\n",
            "Epoch 132/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.5555 - acc: 0.6819 - val_loss: 0.5381 - val_acc: 0.7004\n",
            "Epoch 133/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.5371 - acc: 0.7101 - val_loss: 0.5561 - val_acc: 0.6810\n",
            "Epoch 134/200\n",
            "45/45 [==============================] - 1s 20ms/step - loss: 0.5294 - acc: 0.7111 - val_loss: 0.5137 - val_acc: 0.7254\n",
            "Epoch 135/200\n",
            "45/45 [==============================] - 1s 23ms/step - loss: 0.5038 - acc: 0.7427 - val_loss: 0.4918 - val_acc: 0.7531\n",
            "Epoch 136/200\n",
            "45/45 [==============================] - 1s 25ms/step - loss: 0.5113 - acc: 0.7476 - val_loss: 0.4667 - val_acc: 0.7712\n",
            "Epoch 137/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.5101 - acc: 0.7594 - val_loss: 0.6029 - val_acc: 0.6657\n",
            "Epoch 138/200\n",
            "45/45 [==============================] - 1s 19ms/step - loss: 0.5177 - acc: 0.7493 - val_loss: 0.4302 - val_acc: 0.8114\n",
            "Epoch 139/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.4170 - acc: 0.8222 - val_loss: 0.3822 - val_acc: 0.8239\n",
            "Epoch 140/200\n",
            "45/45 [==============================] - 1s 18ms/step - loss: 0.3800 - acc: 0.8427 - val_loss: 0.3714 - val_acc: 0.8239\n",
            "Epoch 141/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.3774 - acc: 0.8313 - val_loss: 0.3559 - val_acc: 0.8350\n",
            "Epoch 142/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.3277 - acc: 0.8622 - val_loss: 0.3336 - val_acc: 0.8530\n",
            "Epoch 143/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.3146 - acc: 0.8715 - val_loss: 0.3508 - val_acc: 0.8239\n",
            "Epoch 144/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.3127 - acc: 0.8677 - val_loss: 0.3477 - val_acc: 0.8391\n",
            "Epoch 145/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.2925 - acc: 0.8764 - val_loss: 0.3023 - val_acc: 0.8627\n",
            "Epoch 146/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.2876 - acc: 0.8760 - val_loss: 0.2792 - val_acc: 0.8696\n",
            "Epoch 147/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.2915 - acc: 0.8819 - val_loss: 0.2697 - val_acc: 0.8752\n",
            "Epoch 148/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.2594 - acc: 0.8969 - val_loss: 0.2661 - val_acc: 0.8793\n",
            "Epoch 149/200\n",
            "45/45 [==============================] - 1s 19ms/step - loss: 0.2719 - acc: 0.8899 - val_loss: 0.2547 - val_acc: 0.8932\n",
            "Epoch 150/200\n",
            "45/45 [==============================] - 1s 25ms/step - loss: 0.2525 - acc: 0.8979 - val_loss: 0.2561 - val_acc: 0.8835\n",
            "Epoch 151/200\n",
            "45/45 [==============================] - 1s 25ms/step - loss: 0.2622 - acc: 0.8896 - val_loss: 0.2455 - val_acc: 0.8877\n",
            "Epoch 152/200\n",
            "45/45 [==============================] - 1s 19ms/step - loss: 0.2454 - acc: 0.9017 - val_loss: 0.2299 - val_acc: 0.8988\n",
            "Epoch 153/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.2319 - acc: 0.9076 - val_loss: 0.2827 - val_acc: 0.8918\n",
            "Epoch 154/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.2431 - acc: 0.9059 - val_loss: 0.2211 - val_acc: 0.8988\n",
            "Epoch 155/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.2378 - acc: 0.9101 - val_loss: 0.2254 - val_acc: 0.8877\n",
            "Epoch 156/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.2235 - acc: 0.9149 - val_loss: 0.2115 - val_acc: 0.9043\n",
            "Epoch 157/200\n",
            "45/45 [==============================] - 1s 18ms/step - loss: 0.2358 - acc: 0.9080 - val_loss: 0.2062 - val_acc: 0.9112\n",
            "Epoch 158/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.2202 - acc: 0.9167 - val_loss: 0.2358 - val_acc: 0.9043\n",
            "Epoch 159/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.2229 - acc: 0.9142 - val_loss: 0.2012 - val_acc: 0.9126\n",
            "Epoch 160/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.2299 - acc: 0.9118 - val_loss: 0.2131 - val_acc: 0.9001\n",
            "Epoch 161/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.2198 - acc: 0.9163 - val_loss: 0.2012 - val_acc: 0.9085\n",
            "Epoch 162/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.2408 - acc: 0.9069 - val_loss: 0.2100 - val_acc: 0.9085\n",
            "Epoch 163/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.2074 - acc: 0.9187 - val_loss: 0.2136 - val_acc: 0.9098\n",
            "Epoch 164/200\n",
            "45/45 [==============================] - 1s 19ms/step - loss: 0.2063 - acc: 0.9247 - val_loss: 0.2142 - val_acc: 0.9085\n",
            "Epoch 165/200\n",
            "45/45 [==============================] - 1s 24ms/step - loss: 0.2046 - acc: 0.9302 - val_loss: 0.2165 - val_acc: 0.9112\n",
            "Epoch 166/200\n",
            "45/45 [==============================] - 1s 25ms/step - loss: 0.1980 - acc: 0.9278 - val_loss: 0.1919 - val_acc: 0.9196\n",
            "Epoch 167/200\n",
            "45/45 [==============================] - 1s 20ms/step - loss: 0.1973 - acc: 0.9299 - val_loss: 0.2259 - val_acc: 0.9029\n",
            "Epoch 168/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.1957 - acc: 0.9257 - val_loss: 0.1890 - val_acc: 0.9209\n",
            "Epoch 169/200\n",
            "45/45 [==============================] - 1s 19ms/step - loss: 0.1928 - acc: 0.9281 - val_loss: 0.1856 - val_acc: 0.9209\n",
            "Epoch 170/200\n",
            "45/45 [==============================] - 1s 18ms/step - loss: 0.1973 - acc: 0.9240 - val_loss: 0.2528 - val_acc: 0.9057\n",
            "Epoch 171/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.1946 - acc: 0.9306 - val_loss: 0.1953 - val_acc: 0.9098\n",
            "Epoch 172/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.1835 - acc: 0.9302 - val_loss: 0.1775 - val_acc: 0.9140\n",
            "Epoch 173/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.1797 - acc: 0.9323 - val_loss: 0.1770 - val_acc: 0.9237\n",
            "Epoch 174/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.1766 - acc: 0.9358 - val_loss: 0.1693 - val_acc: 0.9237\n",
            "Epoch 175/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.1831 - acc: 0.9340 - val_loss: 0.1718 - val_acc: 0.9279\n",
            "Epoch 176/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.1792 - acc: 0.9361 - val_loss: 0.1978 - val_acc: 0.9098\n",
            "Epoch 177/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.1699 - acc: 0.9382 - val_loss: 0.1690 - val_acc: 0.9237\n",
            "Epoch 178/200\n",
            "45/45 [==============================] - 1s 18ms/step - loss: 0.1761 - acc: 0.9344 - val_loss: 0.2046 - val_acc: 0.9168\n",
            "Epoch 179/200\n",
            "45/45 [==============================] - 1s 19ms/step - loss: 0.1857 - acc: 0.9372 - val_loss: 0.1945 - val_acc: 0.9209\n",
            "Epoch 180/200\n",
            "45/45 [==============================] - 1s 30ms/step - loss: 0.1887 - acc: 0.9292 - val_loss: 0.1757 - val_acc: 0.9293\n",
            "Epoch 181/200\n",
            "45/45 [==============================] - 1s 31ms/step - loss: 0.1748 - acc: 0.9382 - val_loss: 0.2052 - val_acc: 0.9182\n",
            "Epoch 182/200\n",
            "45/45 [==============================] - 1s 29ms/step - loss: 0.1707 - acc: 0.9368 - val_loss: 0.1764 - val_acc: 0.9196\n",
            "Epoch 183/200\n",
            "45/45 [==============================] - 1s 20ms/step - loss: 0.1776 - acc: 0.9323 - val_loss: 0.1856 - val_acc: 0.9223\n",
            "Epoch 184/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.1702 - acc: 0.9365 - val_loss: 0.1841 - val_acc: 0.9293\n",
            "Epoch 185/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.1843 - acc: 0.9347 - val_loss: 0.1883 - val_acc: 0.9251\n",
            "Epoch 186/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.1670 - acc: 0.9399 - val_loss: 0.1738 - val_acc: 0.9251\n",
            "Epoch 187/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.1649 - acc: 0.9413 - val_loss: 0.1845 - val_acc: 0.9209\n",
            "Epoch 188/200\n",
            "45/45 [==============================] - 1s 18ms/step - loss: 0.1702 - acc: 0.9406 - val_loss: 0.1740 - val_acc: 0.9140\n",
            "Epoch 189/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.1741 - acc: 0.9406 - val_loss: 0.1786 - val_acc: 0.9307\n",
            "Epoch 190/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.1698 - acc: 0.9358 - val_loss: 0.2043 - val_acc: 0.9196\n",
            "Epoch 191/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.1763 - acc: 0.9326 - val_loss: 0.1783 - val_acc: 0.9196\n",
            "Epoch 192/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.1554 - acc: 0.9465 - val_loss: 0.1772 - val_acc: 0.9209\n",
            "Epoch 193/200\n",
            "45/45 [==============================] - 1s 18ms/step - loss: 0.1624 - acc: 0.9424 - val_loss: 0.1669 - val_acc: 0.9237\n",
            "Epoch 194/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.1587 - acc: 0.9424 - val_loss: 0.1687 - val_acc: 0.9251\n",
            "Epoch 195/200\n",
            "45/45 [==============================] - 1s 20ms/step - loss: 0.1650 - acc: 0.9434 - val_loss: 0.1690 - val_acc: 0.9307\n",
            "Epoch 196/200\n",
            "45/45 [==============================] - 1s 23ms/step - loss: 0.1606 - acc: 0.9444 - val_loss: 0.1740 - val_acc: 0.9265\n",
            "Epoch 197/200\n",
            "45/45 [==============================] - 1s 24ms/step - loss: 0.1728 - acc: 0.9354 - val_loss: 0.1778 - val_acc: 0.9223\n",
            "Epoch 198/200\n",
            "45/45 [==============================] - 1s 20ms/step - loss: 0.1533 - acc: 0.9451 - val_loss: 0.1679 - val_acc: 0.9251\n",
            "Epoch 199/200\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.1575 - acc: 0.9469 - val_loss: 0.1674 - val_acc: 0.9237\n",
            "Epoch 200/200\n",
            "45/45 [==============================] - 1s 18ms/step - loss: 0.1615 - acc: 0.9417 - val_loss: 0.1666 - val_acc: 0.9265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# carga el modelo\n",
        "model = load_model('GRU.h5')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "\n",
        "# evalua el modelo con evaluate y saca test_loss y test_acc\n",
        "\n",
        "print(\"Test accuracy\", test_acc)\n",
        "print(\"Test loss\", test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-XOXby4tmhz",
        "outputId": "8ceacd92-bbd2-4f6b-ae0d-191d03257ff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 [==============================] - 1s 11ms/step - loss: 0.1657 - acc: 0.9394\n",
            "Test accuracy 0.939393937587738\n",
            "Test loss 0.16572408378124237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzFqRiEOwmHq"
      },
      "source": [
        "# Conclusión\n",
        "\n",
        "Qué puedes decir de estos modelos?\n",
        "\n",
        "Hay sobreajuste?\n",
        "\n",
        "Entrenan bien?\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**CONCLUSIONES**\n",
        "\n",
        "* Se han probado varias combinaciones con **RNN** (32/64 capas, con/sin dropout, batch_size 32/64) sin llegar a superar el 0.51 de accuracy y una pérdida de 0.69.\n",
        "* En RNN vemos sobreajuste y con cambios insignificante a pesar de las capas de Dropout.\n",
        "\n",
        "* Con LSTM también se han probado varias combinaciones, incluso añadiendo dos capas LSTM (64 y 32)  y el máximo accuracy ha sido de 0.51 pero con mucha pérdida.\n",
        "\n",
        "* El resultado con GRU es sorprendente. Con una sola capa GRU, se obtiene un resultado de rendimiento de 0.5. Sin embargo, si añadimos una capa de Dropout, **conseguimos un 0.939 con una pérdida de 0.165**, demostrando así su buen rendimiento.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota**: Para optimizar las redes neuronales, se utiliza una herramienta llamada KerasTuner.\n",
        "[Puedes echarle un vistazo si quieres en este enlace](https://keras.io/keras_tuner/)"
      ],
      "metadata": {
        "id": "sfoImEWWe9pa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iq4QC8qWHSTb",
        "outputId": "33670dff-6065-482a-855d-14136810e206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.7.4)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner\n",
        "\n",
        "def build_model(hp):\n",
        "  model_tuner = Sequential()\n",
        "  model_tuner.add(Dense(\n",
        "      hp.Choice('units', [8, 16, 32]),\n",
        "      activation='relu'))\n",
        "  model_tuner.add(Dense(1, activation='relu'))\n",
        "  model_tuner.compile(loss='mse')\n",
        "  return model_tuner\n",
        "\n",
        "\n",
        "tuner = keras_tuner.RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_loss',\n",
        "    max_trials=5)\n",
        "\n",
        "# Start the search and get the best model\n",
        "tuner.search(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
        "best_model = tuner.get_best_models()[0]\n",
        "\n",
        "print(best_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8bypLbTHvUi",
        "outputId": "205d7973-3c82-4576-dcc6-35dd2ed94567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 00m 06s]\n",
            "val_loss: 0.2504463195800781\n",
            "\n",
            "Best val_loss So Far: 0.2499276101589203\n",
            "Total elapsed time: 00h 00m 20s\n",
            "<keras.src.engine.sequential.Sequential object at 0x7dd1707ae440>\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "L9z3-3LBwmHn"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}